# OpenAI API é›†æˆå®Œæ•´æŠ€æœ¯æ–‡æ¡£

> **ç‰ˆæœ¬**: v1.0 | **æ—¥æœŸ**: 2025-01-25 | **ä½œè€…**: Snow AI | **é¡¹ç›®**: [New-API](https://github.com/Calcium-Ion/new-api)

---

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
- [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
- [è¯·æ±‚å¤„ç†æµç¨‹](#è¯·æ±‚å¤„ç†æµç¨‹)
- [å“åº”å¤„ç†æµç¨‹](#å“åº”å¤„ç†æµç¨‹)
- [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
- [å¤šæ¸ é“æ”¯æŒ](#å¤šæ¸ é“æ”¯æŒ)
- [å®Œæ•´è°ƒç”¨æµç¨‹](#å®Œæ•´è°ƒç”¨æµç¨‹)
- [é…ç½®ä¸éƒ¨ç½²](#é…ç½®ä¸éƒ¨ç½²)

---

## ğŸ¯ æ¦‚è¿°

new-api é¡¹ç›®é€šè¿‡**é€‚é…å™¨æ¨¡å¼**å®ç°å¯¹ OpenAI API çš„å®Œæ•´æ”¯æŒï¼Œä½œä¸ºæ•´ä¸ªç³»ç»Ÿçš„åŸºç¡€æ¶æ„æ¨¡å¼ã€‚OpenAI Adaptor ä¸ä»…æ”¯æŒæ ‡å‡† OpenAI APIï¼Œè¿˜å…¼å®¹ Azure OpenAIã€OpenRouter ç­‰å¤šç§è¡ç”ŸæœåŠ¡ã€‚

### ä¸»è¦ç‰¹æ€§

âœ… **å¤šæ ¼å¼å…¼å®¹** - OpenAI / Claude / Gemini æ ¼å¼äº’è½¬  
âœ… **å…¨æ¨¡æ€æ”¯æŒ** - æ–‡æœ¬ã€è¯­éŸ³ã€å›¾åƒã€å®æ—¶é€šä¿¡  
âœ… **æµå¼å¤„ç†** - SSE æµå¼å“åº” + WebSocket å®æ—¶é€šä¿¡  
âœ… **æ¨ç†æ¨¡å‹** - O1/O3/GPT-5 ç³»åˆ—æ¨ç†æ¨¡å‹æ”¯æŒ  
âœ… **å¤šæ¸ é“æ¶æ„** - è´Ÿè½½å‡è¡¡ã€è‡ªåŠ¨æ•…éšœè½¬ç§»ã€é‡è¯•æœºåˆ¶  
âœ… **ç¼“å­˜è®¡è´¹** - Cache Billing (Azure/DeepSeek/Qwen)  
âœ… **ä¼ä¸šçº§åŠŸèƒ½** - é…é¢ç®¡ç†ã€å¤šç§Ÿæˆ·ã€å®¡è®¡æ—¥å¿—

### æ”¯æŒçš„ API ç±»å‹

| API ç±»å‹ | ç«¯ç‚¹ | è¯´æ˜ |
|---------|------|-----|
| Chat Completions | `/v1/chat/completions` | èŠå¤©è¡¥å…¨ï¼ˆæµå¼/éæµå¼ï¼‰ |
| Embeddings | `/v1/embeddings` | å‘é‡åµŒå…¥ |
| Audio Speech | `/v1/audio/speech` | æ–‡æœ¬è½¬è¯­éŸ³ (TTS) |
| Audio Transcriptions | `/v1/audio/transcriptions` | è¯­éŸ³è½¬æ–‡æœ¬ (STT) |
| Audio Translations | `/v1/audio/translations` | è¯­éŸ³ç¿»è¯‘ |
| Realtime | `/v1/realtime` | WebSocket å®æ—¶é€šä¿¡ |
| Images | `/v1/images/generations` | å›¾åƒç”Ÿæˆ |
| Moderations | `/v1/moderations` | å†…å®¹å®¡æ ¸ |

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„æµç¨‹

```
Client Request
       â†“
[Router Layer] - router/relay-router.go
  â”œâ”€ /v1/chat/completions
  â”œâ”€ /v1/embeddings
  â”œâ”€ /v1/audio/*
  â””â”€ /v1/realtime
       â†“
[Middleware Stack]
  â”œâ”€ CORS
  â”œâ”€ TokenAuth (APIå¯†é’¥éªŒè¯)
  â”œâ”€ ModelRequestRateLimit (é™æµ)
  â””â”€ Distribute (æ¸ é“é€‰æ‹©)
       â†“
[Controller] - controller/relay.go
  â”œâ”€ Relay(c *gin.Context, relayFormat)
  â”œâ”€ è§£æè¯·æ±‚ä½“
  â”œâ”€ éªŒè¯Token/é…é¢
  â””â”€ è°ƒç”¨ relayHandler()
       â†“
[Relay Handler]
  â”œâ”€ GetAdaptor(apiType) - è·å–é€‚é…å™¨
  â”œâ”€ åˆå§‹åŒ– RelayInfo ä¸Šä¸‹æ–‡
  â””â”€ è·¯ç”±åˆ°ç‰¹å®šæ¨¡å¼å¤„ç†å™¨
       â†“
[OpenAI Adaptor] - relay/channel/openai/adaptor.go
  â”œâ”€ ConvertOpenAIRequest() - è¯·æ±‚è½¬æ¢
  â”œâ”€ GetRequestURL() - æ„å»ºç›®æ ‡URL
  â”œâ”€ SetupRequestHeader() - æ·»åŠ è®¤è¯å¤´
  â””â”€ DoRequest() - æ‰§è¡ŒHTTPè°ƒç”¨
       â†“
[External OpenAI API]
       â†“
[Response Handler] - relay/channel/openai/relay-openai.go
  â”œâ”€ DoResponse() - è·¯ç”±åˆ°å“åº”å¤„ç†å™¨
  â”œâ”€ å¤„ç†æµå¼/éæµå¼å“åº”
  â”œâ”€ Tokenè®¡æ•°ï¼ˆè®¡è´¹ï¼‰
  â””â”€ è¿”å›æ ¼å¼åŒ–å“åº”
       â†“
Client receives response
```

### æ–‡ä»¶ç»“æ„

```
relay/channel/openai/
â”œâ”€â”€ adaptor.go              # æ ¸å¿ƒé€‚é…å™¨ï¼ˆè¯·æ±‚è½¬æ¢ã€URLæ„å»ºã€è®¤è¯ï¼‰
â”œâ”€â”€ relay-openai.go         # å“åº”å¤„ç†å™¨ï¼ˆæµå¼/éæµå¼ï¼‰
â”œâ”€â”€ audio.go                # éŸ³é¢‘APIå¤„ç†ï¼ˆTTS/STTï¼‰
â”œâ”€â”€ realtime.go             # WebSocketå®æ—¶é€šä¿¡
â””â”€â”€ token.go                # Tokenè®¡æ•°å·¥å…·

controller/
â””â”€â”€ relay.go                # ä¸»æ§åˆ¶å™¨ï¼ˆè¯·æ±‚åˆ†å‘ã€æ¸ é“é€‰æ‹©ï¼‰

middleware/
â”œâ”€â”€ auth.go                 # Tokenè®¤è¯ä¸­é—´ä»¶
â”œâ”€â”€ distributor.go          # æ¸ é“åˆ†é…ä¸è´Ÿè½½å‡è¡¡
â””â”€â”€ rate-limit.go           # é™æµä¸­é—´ä»¶

router/
â””â”€â”€ relay-router.go         # è·¯ç”±å®šä¹‰

service/
â”œâ”€â”€ convert.go              # æ ¼å¼è½¬æ¢ï¼ˆOpenAI â†” Claude â†” Geminiï¼‰
â””â”€â”€ token_counter.go        # Tokenè®¡æ•°æœåŠ¡ï¼ˆtiktokenï¼‰

model/
â”œâ”€â”€ channel.go              # æ¸ é“æ•°æ®æ¨¡å‹
â””â”€â”€ token.go                # Tokenæ•°æ®æ¨¡å‹

dto/
â”œâ”€â”€ openai.go               # OpenAIè¯·æ±‚/å“åº”DTO
â”œâ”€â”€ claude.go               # Claude DTO
â””â”€â”€ gemini.go               # Gemini DTO
```

---

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### 1. Adaptor ç»“æ„ä½“

**æ–‡ä»¶**: `relay/channel/openai/adaptor.go`

```go
type Adaptor struct {
    ChannelType    int    // æ¸ é“ç±»å‹ï¼ˆOpenAI/Azure/OpenRouterï¼‰
    ResponseFormat string // å“åº”æ ¼å¼å¼ºåˆ¶è½¬æ¢
}
```

**æ ¸å¿ƒåŠŸèƒ½**:
- å®ç° `channel.Adaptor` æ¥å£
- æ”¯æŒå¤šç§è¯·æ±‚æ ¼å¼ï¼ˆOpenAI/Claude/Geminiï¼‰è‡ªåŠ¨è¯†åˆ«ä¸è½¬æ¢
- å¤„ç†ä¸åŒæ¨¡å‹çš„ç‰¹æ®Šéœ€æ±‚ï¼ˆOç³»åˆ—ã€GPT-4ã€Azureç‰¹å®šé…ç½®ï¼‰
- ç»Ÿä¸€çš„é”™è¯¯å¤„ç†ä¸é‡è¯•é€»è¾‘

### 2. æ ¸å¿ƒæ–¹æ³•è¯¦è§£

#### 2.1 Init() - åˆå§‹åŒ–

```go
func (a *Adaptor) Init(info *relaycommon.RelayInfo) {}
```

**åŠŸèƒ½**:
- è®¾ç½®æ¸ é“ç±»å‹ï¼ˆOpenAIã€Azureã€OpenRouterç­‰ï¼‰
- æ ¹æ®æ¸ é“é…ç½®åˆå§‹åŒ–å“åº”æ ¼å¼è½¬æ¢é€‰é¡¹

---

#### 2.2 ConvertOpenAIRequest() - è¯·æ±‚è½¬æ¢

**æ–‡ä»¶**: `relay/channel/openai/adaptor.go`

```go
func (a *Adaptor) ConvertOpenAIRequest(c *gin.Context, info *relaycommon.RelayInfo, request *dto.GeneralOpenAIRequest) error
```

**è½¬æ¢é€»è¾‘**:

##### A. Oç³»åˆ—æ¨¡å‹ç‰¹æ®Šå¤„ç†ï¼ˆO1/O3/GPT-5ï¼‰

```go
if strings.HasPrefix(info.UpstreamModelName, "o") {
    // 1. max_tokens â†’ max_completion_tokens
    if request.MaxCompletionTokens == 0 && request.MaxTokens != 0 {
        request.MaxCompletionTokens = request.MaxTokens
        request.MaxTokens = 0
    }
    
    // 2. ç¦ç”¨temperatureï¼ˆOç³»åˆ—ä¸æ”¯æŒï¼‰
    request.Temperature = nil
    
    // 3. system â†’ developerï¼ˆè¾ƒæ–°Oç³»åˆ—æ¨¡å‹ï¼‰
    if request.Messages[0].Role == "system" {
        request.Messages[0].Role = "developer"
    }
    
    // 4. è§£ææ¨ç†å¼ºåº¦ï¼ˆä»æ¨¡å‹ååç¼€ï¼‰
    // ä¾‹å¦‚: "o1-mini-high" â†’ reasoning_effort: "high"
    if strings.Contains(info.UpstreamModelName, "-high") {
        request.ReasoningEffort = "high"
    } else if strings.Contains(info.UpstreamModelName, "-medium") {
        request.ReasoningEffort = "medium"
    } else if strings.Contains(info.UpstreamModelName, "-low") {
        request.ReasoningEffort = "low"
    }
}
```

##### B. Stream Options é…ç½®

```go
// OpenAI/Azure: æ·»åŠ  stream_options ä»¥è·å–ä½¿ç”¨ç»Ÿè®¡
if request.Stream && a.ChannelType == constant.ChannelTypeOpenAI {
    if request.StreamOptions == nil {
        request.StreamOptions = &dto.StreamOptions{}
    }
    request.StreamOptions.IncludeUsage = true
    info.SupportStreamOptions = true
}
```

##### C. Claude/Gemini æ ¼å¼è‡ªåŠ¨è½¬æ¢

```go
// æ£€æµ‹è¯·æ±‚æ ¼å¼ï¼ˆé€šè¿‡ç»“æ„æˆ–Headerï¼‰
if isClaudeFormat(request) {
    claudeReq := parseClaudeRequest(request)
    request = service.ClaudeToOpenAIRequest(claudeReq, info)
}

if isGeminiFormat(request) {
    geminiReq := parseGeminiRequest(request)
    request = service.GeminiToOpenAIRequest(geminiReq, info)
}
```

##### D. OpenRouter ç‰¹æ®Šå¤„ç†

```go
// OpenRouterçš„-thinkingåç¼€æ¨¡å‹è½¬æ¢ä¸ºæ¨ç†API
if a.ChannelType == constant.ChannelTypeOpenRouter {
    if strings.HasSuffix(info.UpstreamModelName, "-thinking") {
        info.UpstreamModelName = strings.TrimSuffix(info.UpstreamModelName, "-thinking")
        // æ·»åŠ æ¨ç†ç›¸å…³å‚æ•°
    }
}
```

---

#### 2.3 GetRequestURL() - URLæ„å»º

**æ–‡ä»¶**: `relay/channel/openai/adaptor.go`

```go
func (a *Adaptor) GetRequestURL(info *relaycommon.RelayInfo) (string, error)
```

**æ”¯æŒçš„URLæ ¼å¼**:

##### A. Azure OpenAI

```go
// æ ¼å¼: https://{base-url}/openai/deployments/{model}/chat/completions?api-version={version}
fullRequestURL := fmt.Sprintf("%s/openai/deployments/%s/%s?api-version=%s",
    baseURL,
    info.UpstreamModelName,
    requestPath,
    info.ApiVersion, // ä¾‹å¦‚: 2024-02-15-preview
)
```

**æ³¨æ„äº‹é¡¹**:
- éœ€è¦é…ç½® `api-version`ï¼ˆé€šè¿‡æ¸ é“è®¾ç½®ï¼‰
- æ¨¡å‹åä½œä¸º deployment name
- æ”¯æŒè‡ªå®šä¹‰ç«¯ç‚¹

##### B. æ ‡å‡† OpenAI

```go
// æ ¼å¼: https://api.openai.com/v1/{endpoint}
fullRequestURL := fmt.Sprintf("%s/%s", baseURL, requestPath)
// ä¾‹å¦‚: https://api.openai.com/v1/chat/completions
```

##### C. è‡ªå®šä¹‰æ¸ é“ï¼ˆæ”¯æŒå ä½ç¬¦ï¼‰

```go
// æ¸ é“é…ç½®æ”¯æŒ {model} å ä½ç¬¦æ›¿æ¢
if strings.Contains(baseURL, "{model}") {
    fullRequestURL = strings.Replace(baseURL, "{model}", info.UpstreamModelName, -1)
}
```

##### D. WebSocket å®æ—¶API

```go
// wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview
fullRequestURL := fmt.Sprintf("wss://%s/v1/realtime?model=%s",
    strings.TrimPrefix(baseURL, "https://"),
    info.UpstreamModelName,
)
```

---

#### 2.4 SetupRequestHeader() - è¯·æ±‚å¤´è®¾ç½®

**æ–‡ä»¶**: `relay/channel/openai/adaptor.go`

```go
func (a *Adaptor) SetupRequestHeader(c *gin.Context, header *http.Header, info *relaycommon.RelayInfo) error
```

**è®¤è¯å¤´é…ç½®**:

##### A. Azure OpenAI è®¤è¯

```go
if info.ChannelType == constant.ChannelTypeAzure {
    header.Set("api-key", info.ApiKey)  // Azureä¸“ç”¨header
}
```

##### B. æ ‡å‡† OpenAI è®¤è¯

```go
else {
    header.Set("Authorization", "Bearer " + info.ApiKey)
    
    // å¯é€‰: OpenAI Organization
    if info.Organization != "" {
        header.Set("OpenAI-Organization", info.Organization)
    }
}
```

##### C. å…¶ä»–æ ‡å‡†å¤´

```go
header.Set("Content-Type", "application/json")
header.Set("Accept", "application/json")

// User-Agent
header.Set("User-Agent", "new-api/1.0")
```

---

#### 2.5 DoRequest() - æ‰§è¡ŒHTTPè¯·æ±‚

**æ–‡ä»¶**: `relay/channel/openai/adaptor.go`

```go
func (a *Adaptor) DoRequest(c *gin.Context, info *relaycommon.RelayInfo, requestBody io.Reader) (*http.Response, error)
```

**è¯·æ±‚æ‰§è¡Œæµç¨‹**:

```go
// 1. æ„å»ºHTTPè¯·æ±‚
req, err := http.NewRequest("POST", fullRequestURL, requestBody)

// 2. è®¾ç½®è¯·æ±‚å¤´
a.SetupRequestHeader(c, &req.Header, info)

// 3. è¶…æ—¶æ§åˆ¶
client := &http.Client{
    Timeout: time.Duration(info.Timeout) * time.Second,
}

// 4. æ‰§è¡Œè¯·æ±‚
resp, err := client.Do(req)

// 5. é”™è¯¯æ£€æŸ¥
if err != nil {
    return nil, fmt.Errorf("request failed: %w", err)
}

return resp, nil
```

---

#### 2.6 DoResponse() - å“åº”å¤„ç†åˆ†å‘

**æ–‡ä»¶**: `relay/channel/openai/relay-openai.go`

```go
func (a *Adaptor) DoResponse(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo) (usage *dto.Usage, err *types.NewAPIError)
```

**å“åº”å¤„ç†è·¯ç”±**:

```go
switch info.RelayMode {
case constant.RelayModeChatCompletions:
    if info.IsStream {
        // æµå¼å“åº”
        usage, err = OaiStreamHandler(c, resp, info, a.ResponseFormat)
    } else {
        // éæµå¼å“åº”
        usage, err = OpenaiHandler(c, resp, info, a.ResponseFormat)
    }

case constant.RelayModeAudioSpeech:
    // TTS: è¿”å›éŸ³é¢‘æµ
    usage, err = OpenaiTTSHandler(c, resp, info)

case constant.RelayModeAudioTranscription:
    // STT: è¿”å›æ–‡æœ¬
    usage, err = OpenaiSTTHandler(c, resp, info)

case constant.RelayModeImagesGenerations:
    // å›¾åƒç”Ÿæˆ
    usage, err = OpenaiHandlerWithUsage(c, resp, info)

case constant.RelayModeRealtime:
    // WebSocketå®æ—¶é€šä¿¡ï¼ˆåœ¨å…¶ä»–åœ°æ–¹å¤„ç†ï¼‰
    return nil, nil
}
```

---

## ğŸ“¨ è¯·æ±‚å¤„ç†æµç¨‹

### 1. è·¯ç”±å±‚ï¼ˆRouterï¼‰

**æ–‡ä»¶**: `router/relay-router.go`

```go
func SetRelayRouter(router *gin.Engine) {
    relayV1Router := router.Group("/v1")
    
    // Chat Completions
    relayV1Router.POST("/chat/completions", func(c *gin.Context) {
        controller.Relay(c, types.RelayFormatOpenAI)
    })
    
    // Embeddings
    relayV1Router.POST("/embeddings", func(c *gin.Context) {
        controller.Relay(c, types.RelayFormatEmbedding)
    })
    
    // Audio APIs
    audioRouter := relayV1Router.Group("/audio")
    {
        audioRouter.POST("/speech", func(c *gin.Context) {
            controller.Relay(c, types.RelayFormatAudioSpeech)
        })
        
        audioRouter.POST("/transcriptions", func(c *gin.Context) {
            controller.Relay(c, types.RelayFormatAudioTranscription)
        })
        
        audioRouter.POST("/translations", func(c *gin.Context) {
            controller.Relay(c, types.RelayFormatAudioTranslation)
        })
    }
    
    // Realtime (WebSocket)
    relayV1Router.GET("/realtime", func(c *gin.Context) {
        controller.Relay(c, types.RelayFormatOpenAIRealtime)
    })
    
    // Images
    relayV1Router.POST("/images/generations", func(c *gin.Context) {
        controller.Relay(c, types.RelayFormatImagesGenerations)
    })
}
```

### 2. ä¸­é—´ä»¶æ ˆï¼ˆMiddlewareï¼‰

#### 2.1 Tokenè®¤è¯

**æ–‡ä»¶**: `middleware/auth.go`

```go
func TokenAuth() func(c *gin.Context) {
    return func(c *gin.Context) {
        // 1. æå–Token
        key := c.Request.Header.Get("Authorization")
        key = strings.TrimPrefix(key, "Bearer ")
        
        // 2. æ•°æ®åº“éªŒè¯
        token := model.ValidateUserToken(key)
        if token == nil {
            c.JSON(401, gin.H{"error": "Invalid token"})
            c.Abort()
            return
        }
        
        // 3. æ£€æŸ¥é…é¢
        if token.RemainQuota <= 0 {
            c.JSON(429, gin.H{"error": "Quota exceeded"})
            c.Abort()
            return
        }
        
        // 4. è®¾ç½®ä¸Šä¸‹æ–‡
        SetupContextForToken(c, token)
        c.Next()
    }
}
```

#### 2.2 æ¸ é“åˆ†é…ï¼ˆChannel Distributionï¼‰

**æ–‡ä»¶**: `middleware/distributor.go`

```go
func Distribute() func(c *gin.Context) {
    return func(c *gin.Context) {
        // 1. è·å–å¯ç”¨æ¸ é“åˆ—è¡¨
        channels := model.GetAvailableChannels(modelName)
        
        // 2. åŠ æƒéšæœºé€‰æ‹©
        channel := selectChannelByWeight(channels)
        
        // 3. å¥åº·æ£€æŸ¥
        if !channel.IsHealthy() {
            // å°è¯•ä¸‹ä¸€ä¸ªæ¸ é“
            channel = fallbackChannel(channels)
        }
        
        // 4. è®¾ç½®æ¸ é“ä¿¡æ¯åˆ°ä¸Šä¸‹æ–‡
        c.Set("channel", channel)
        c.Next()
    }
}
```

**é€‰æ‹©ç­–ç•¥**:
- **åŠ æƒéšæœº**: æ ¹æ®æ¸ é“ä¼˜å…ˆçº§ï¼ˆPriorityå­—æ®µï¼‰åŠ æƒ
- **å¥åº·æ£€æŸ¥**: è¿‡æ»¤æ‰å¤±è´¥æ¬¡æ•°è¿‡å¤šçš„æ¸ é“
- **è‡ªåŠ¨æ•…éšœè½¬ç§»**: è¯·æ±‚å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ¸ é“

### 3. æ§åˆ¶å™¨å±‚ï¼ˆControllerï¼‰

**æ–‡ä»¶**: `controller/relay.go`

```go
func Relay(c *gin.Context, relayFormat types.RelayFormat) {
    // 1. è§£æè¯·æ±‚ä½“
    var request dto.GeneralOpenAIRequest
    if err := c.ShouldBindJSON(&request); err != nil {
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }
    
    // 2. è·å–Tokenå’Œæ¸ é“ä¿¡æ¯
    token := c.GetInt("token_id")
    channel := c.MustGet("channel").(model.Channel)
    
    // 3. æ„å»ºRelayInfoä¸Šä¸‹æ–‡
    info := buildRelayInfo(c, token, channel, &request)
    
    // 4. è°ƒç”¨relayå¤„ç†
    usage, err := relayHandler(c, info, &request)
    
    // 5. æ‰£é™¤é…é¢
    if err == nil {
        deductQuota(token, usage)
    }
    
    // 6. è®°å½•æ—¥å¿—
    logRequest(info, usage, err)
}
```

### 4. Relay Handlerï¼ˆæ ¸å¿ƒå¤„ç†ï¼‰

**æ–‡ä»¶**: `controller/relay.go`

```go
func relayHandler(c *gin.Context, info *relaycommon.RelayInfo, request *dto.GeneralOpenAIRequest) (*dto.Usage, *types.NewAPIError) {
    // 1. è·å–é€‚é…å™¨
    adaptor := relay.GetAdaptor(info.ChannelType)
    
    // 2. åˆå§‹åŒ–é€‚é…å™¨
    adaptor.Init(info)
    
    // 3. è½¬æ¢è¯·æ±‚
    if err := adaptor.ConvertOpenAIRequest(c, info, request); err != nil {
        return nil, types.NewAPIError(400, err.Error())
    }
    
    // 4. åºåˆ—åŒ–è¯·æ±‚ä½“
    requestBody, _ := json.Marshal(request)
    
    // 5. æ‰§è¡Œè¯·æ±‚
    resp, err := adaptor.DoRequest(c, info, bytes.NewReader(requestBody))
    if err != nil {
        // é‡è¯•é€»è¾‘
        if shouldRetry(err) {
            return retryRequest(c, info, request, adaptor)
        }
        return nil, types.NewAPIError(500, err.Error())
    }
    
    // 6. å¤„ç†å“åº”
    usage, apiErr := adaptor.DoResponse(c, resp, info)
    
    return usage, apiErr
}
```

**é‡è¯•ç­–ç•¥**:

```go
func shouldRetry(err *types.NewAPIError) bool {
    // 429: Rate limit
    // 500-504: Server errors
    retryableStatusCodes := []int{429, 500, 502, 503, 504}
    return contains(retryableStatusCodes, err.StatusCode)
}

func retryRequest(c *gin.Context, info *relaycommon.RelayInfo, request *dto.GeneralOpenAIRequest, adaptor channel.Adaptor) (*dto.Usage, *types.NewAPIError) {
    maxRetries := 3
    for i := 0; i < maxRetries; i++ {
        time.Sleep(time.Duration(i+1) * time.Second) // æŒ‡æ•°é€€é¿
        
        resp, err := adaptor.DoRequest(c, info, getRequestBody(request))
        if err == nil {
            return adaptor.DoResponse(c, resp, info)
        }
    }
    return nil, types.NewAPIError(500, "Max retries exceeded")
}
```

---

## ğŸ“¤ å“åº”å¤„ç†æµç¨‹

### 1. æµå¼å“åº”å¤„ç†ï¼ˆStreamingï¼‰

**æ–‡ä»¶**: `relay/channel/openai/relay-openai.go`

```go
func OaiStreamHandler(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo, responseFormat string) (usage *dto.Usage, err *types.NewAPIError) {
    // 1. è®¾ç½®SSEå“åº”å¤´
    c.Writer.Header().Set("Content-Type", "text/event-stream")
    c.Writer.Header().Set("Cache-Control", "no-cache")
    c.Writer.Header().Set("Connection", "keep-alive")
    
    // 2. åˆå§‹åŒ–Tokenè®¡æ•°å™¨
    usage = &dto.Usage{}
    
    // 3. é€è¡Œè¯»å–SSEæµ
    scanner := bufio.NewScanner(resp.Body)
    for scanner.Scan() {
        line := scanner.Text()
        
        // è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
        if line == "" || strings.HasPrefix(line, ":") {
            continue
        }
        
        // æå–dataå†…å®¹
        if strings.HasPrefix(line, "data: ") {
            data := strings.TrimPrefix(line, "data: ")
            
            // ç»“æŸæ ‡è®°
            if data == "[DONE]" {
                c.Writer.Write([]byte("data: [DONE]\n\n"))
                c.Writer.Flush()
                break
            }
            
            // 4. è§£æJSON chunk
            var chunk dto.ChatCompletionsStreamResponse
            if err := json.Unmarshal([]byte(data), &chunk); err != nil {
                continue
            }
            
            // 5. å¤„ç†chunkå†…å®¹
            if len(chunk.Choices) > 0 {
                delta := chunk.Choices[0].Delta
                
                // ç´¯åŠ Tokenè®¡æ•°
                if delta.Content != "" {
                    usage.CompletionTokens += countTokens(delta.Content)
                }
                
                // å¤„ç†æ¨ç†å†…å®¹ï¼ˆreasoning_contentï¼‰
                if delta.ReasoningContent != "" && info.ThinkingToContent {
                    // è½¬æ¢ä¸º<think>æ ‡ç­¾æ ¼å¼
                    delta.Content = fmt.Sprintf("<think>\n%s\n</think>\n%s", 
                        delta.ReasoningContent, delta.Content)
                    delta.ReasoningContent = ""
                }
                
                // å¤„ç†å·¥å…·è°ƒç”¨
                if len(delta.ToolCalls) > 0 {
                    // ç´¯åŠ å·¥å…·è°ƒç”¨Token
                    usage.CompletionTokens += countToolCallTokens(delta.ToolCalls)
                }
            }
            
            // 6. æå–ä½¿ç”¨ç»Ÿè®¡ï¼ˆæœ€åä¸€ä¸ªchunkï¼‰
            if chunk.Usage != nil {
                usage.PromptTokens = chunk.Usage.PromptTokens
                usage.CompletionTokens = chunk.Usage.CompletionTokens
                usage.TotalTokens = chunk.Usage.TotalTokens
            }
            
            // 7. æ ¼å¼è½¬æ¢ï¼ˆå¦‚éœ€è¦ï¼‰
            if responseFormat == "claude" {
                data = convertToClaudeStream(chunk)
            } else if responseFormat == "gemini" {
                data = convertToGeminiStream(chunk)
            }
            
            // 8. è½¬å‘ç»™å®¢æˆ·ç«¯
            c.Writer.Write([]byte("data: " + data + "\n\n"))
            c.Writer.Flush()
        }
    }
    
    return usage, nil
}
```

**ç‰¹æ®Šå¤„ç†**:

##### A. éŸ³é¢‘æ¨¡å‹ï¼ˆAudio Modelsï¼‰

```go
// éŸ³é¢‘æ¨¡å‹çš„usageåœ¨å€’æ•°ç¬¬äºŒä¸ªäº‹ä»¶ä¸­
if info.IsAudioModel {
    // ç¼“å­˜æœ€åä¸¤ä¸ªäº‹ä»¶
    if secondToLastEvent.Usage != nil {
        usage = secondToLastEvent.Usage
    }
}
```

##### B. æ¨ç†å†…å®¹è½¬æ¢ï¼ˆThinking to Contentï¼‰

```go
// Oç³»åˆ—æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹å¯é€‰è½¬æ¢ä¸ºæ™®é€šå†…å®¹
if info.ThinkingToContent && delta.ReasoningContent != "" {
    delta.Content = fmt.Sprintf("<think>\n%s\n</think>\n%s",
        delta.ReasoningContent,
        delta.Content,
    )
    delta.ReasoningContent = ""
    chunk.Choices[0].Delta = delta
}
```

### 2. éæµå¼å“åº”å¤„ç†

**æ–‡ä»¶**: `relay/channel/openai/relay-openai.go`

```go
func OpenaiHandler(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo, responseFormat string) (usage *dto.Usage, err *types.NewAPIError) {
    // 1. è¯»å–å®Œæ•´å“åº”ä½“
    body, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, types.NewAPIError(500, "Failed to read response")
    }
    
    // 2. è§£æJSON
    var openaiResp dto.OpenAITextResponse
    if err := json.Unmarshal(body, &openaiResp); err != nil {
        return nil, types.NewAPIError(500, "Invalid response format")
    }
    
    // 3. æå–ä½¿ç”¨ç»Ÿè®¡
    usage = openaiResp.Usage
    if usage == nil {
        usage = &dto.Usage{}
    }
    
    // 4. è®¡ç®—ç¼ºå¤±çš„Tokenè®¡æ•°
    if usage.CompletionTokens == 0 {
        for _, choice := range openaiResp.Choices {
            usage.CompletionTokens += countTokens(choice.Message.Content)
            // å·¥å…·è°ƒç”¨Token
            for _, toolCall := range choice.Message.ToolCalls {
                usage.CompletionTokens += countTokens(toolCall.Function.Arguments)
            }
        }
    }
    
    if usage.PromptTokens == 0 && info.PromptTokens > 0 {
        usage.PromptTokens = info.PromptTokens
    }
    
    usage.TotalTokens = usage.PromptTokens + usage.CompletionTokens
    
    // 5. æ ¼å¼è½¬æ¢
    var responseData interface{} = openaiResp
    
    if responseFormat == "claude" {
        responseData = service.ResponseOpenAI2Claude(&openaiResp, info)
    } else if responseFormat == "gemini" {
        responseData = service.ResponseOpenAI2Gemini(&openaiResp, info)
    }
    
    // 6. è¿”å›å“åº”
    c.JSON(resp.StatusCode, responseData)
    
    return usage, nil
}
```

### 3. éŸ³é¢‘å“åº”å¤„ç†

#### 3.1 TTS (Text-to-Speech)

**æ–‡ä»¶**: `relay/channel/openai/audio.go`

```go
func OpenaiTTSHandler(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo) (usage *dto.Usage, err *types.NewAPIError) {
    // 1. è®¾ç½®éŸ³é¢‘å“åº”å¤´
    c.Writer.Header().Set("Content-Type", resp.Header.Get("Content-Type")) // audio/mpeg
    
    // 2. æµå¼è½¬å‘éŸ³é¢‘æ•°æ®
    written, err := io.Copy(c.Writer, resp.Body)
    if err != nil {
        return nil, types.NewAPIError(500, "Audio streaming failed")
    }
    
    // 3. è®¡ç®—Tokenï¼ˆåŸºäºæ–‡æœ¬é•¿åº¦ä¼°ç®—ï¼‰
    usage = &dto.Usage{
        PromptTokens:      info.PromptTokens, // åŸå§‹æ–‡æœ¬Tokenæ•°
        CompletionTokens:  0,
        TotalTokens:       info.PromptTokens,
    }
    
    logger.Info(c, fmt.Sprintf("TTS generated %d bytes audio", written))
    
    return usage, nil
}
```

#### 3.2 STT (Speech-to-Text)

**æ–‡ä»¶**: `relay/channel/openai/audio.go`

```go
func OpenaiSTTHandler(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo) (usage *dto.Usage, err *types.NewAPIError) {
    // 1. è¯»å–è½¬å†™ç»“æœ
    body, _ := io.ReadAll(resp.Body)
    
    var sttResp dto.AudioTranscriptionResponse
    json.Unmarshal(body, &sttResp)
    
    // 2. è®¡ç®—Tokenï¼ˆåŸºäºéŸ³é¢‘æ—¶é•¿å’Œè¾“å‡ºæ–‡æœ¬ï¼‰
    usage = &dto.Usage{
        PromptTokens:     info.AudioDurationTokens,  // éŸ³é¢‘æ—¶é•¿â†’Tokenï¼ˆæŒ‰ç§’è®¡ç®—ï¼‰
        CompletionTokens: countTokens(sttResp.Text), // è½¬å†™æ–‡æœ¬Token
    }
    usage.TotalTokens = usage.PromptTokens + usage.CompletionTokens
    
    // 3. è¿”å›è½¬å†™ç»“æœ
    c.JSON(200, sttResp)
    
    return usage, nil
}
```

### 4. WebSocketå®æ—¶é€šä¿¡

**æ–‡ä»¶**: `relay/channel/openai/realtime.go`

```go
func OpenaiRealtimeHandler(c *gin.Context, info *relaycommon.RelayInfo) (usage *dto.Usage, err *types.NewAPIError) {
    // 1. å‡çº§HTTPä¸ºWebSocket
    upgrader := websocket.Upgrader{
        CheckOrigin: func(r *http.Request) bool { return true },
    }
    
    clientConn, err := upgrader.Upgrade(c.Writer, c.Request, nil)
    if err != nil {
        return nil, types.NewAPIError(500, "WebSocket upgrade failed")
    }
    defer clientConn.Close()
    
    // 2. è¿æ¥åˆ°OpenAI WebSocket
    targetURL := fmt.Sprintf("wss://api.openai.com/v1/realtime?model=%s", info.UpstreamModelName)
    
    dialer := websocket.Dialer{}
    header := http.Header{}
    header.Set("Authorization", "Bearer "+info.ApiKey)
    header.Set("OpenAI-Beta", "realtime=v1")
    
    targetConn, _, err := dialer.Dial(targetURL, header)
    if err != nil {
        return nil, types.NewAPIError(500, "Failed to connect to OpenAI")
    }
    defer targetConn.Close()
    
    // 3. åŒå‘æ¶ˆæ¯è½¬å‘
    usage = &dto.Usage{}
    
    // Client â†’ OpenAI
    go func() {
        for {
            messageType, message, err := clientConn.ReadMessage()
            if err != nil {
                break
            }
            
            // è½¬å‘æ¶ˆæ¯
            targetConn.WriteMessage(messageType, message)
            
            // è®¡ç®—Tokenï¼ˆéŸ³é¢‘/æ–‡æœ¬ï¼‰
            usage.PromptTokens += estimateTokens(message)
        }
    }()
    
    // OpenAI â†’ Client
    for {
        messageType, message, err := targetConn.ReadMessage()
        if err != nil {
            break
        }
        
        // è½¬å‘å“åº”
        clientConn.WriteMessage(messageType, message)
        
        // è®¡ç®—Token
        usage.CompletionTokens += estimateTokens(message)
    }
    
    usage.TotalTokens = usage.PromptTokens + usage.CompletionTokens
    
    return usage, nil
}
```

---

## ğŸš€ é«˜çº§åŠŸèƒ½

### 1. æ¨ç†æ¨¡å‹æ”¯æŒï¼ˆReasoning Modelsï¼‰

æ”¯æŒ OpenAI çš„æ¨ç†ç³»åˆ—æ¨¡å‹ï¼ˆO1/O3/GPT-5ï¼‰çš„ç‰¹æ®ŠåŠŸèƒ½ã€‚

#### 1.1 æ¨ç†å¼ºåº¦ï¼ˆReasoning Effortï¼‰

**ä»æ¨¡å‹ååç¼€è§£æ**:

```go
// æ”¯æŒæ ¼å¼: o1-mini-high, o1-preview-medium, o3-low
func parseReasoningEffort(modelName string) string {
    if strings.HasSuffix(modelName, "-high") {
        return "high"
    } else if strings.HasSuffix(modelName, "-medium") {
        return "medium"
    } else if strings.HasSuffix(modelName, "-low") {
        return "low"
    }
    return "" // ä½¿ç”¨é»˜è®¤å€¼
}

// åº”ç”¨åˆ°è¯·æ±‚
if effort := parseReasoningEffort(info.UpstreamModelName); effort != "" {
    request.ReasoningEffort = effort
    // æ¸…ç†æ¨¡å‹ååç¼€
    info.UpstreamModelName = strings.TrimSuffix(info.UpstreamModelName, "-"+effort)
}
```

#### 1.2 æ¨ç†å†…å®¹å¤„ç†ï¼ˆReasoning Contentï¼‰

**Streamingæ¨¡å¼**:

```go
// SSEæµä¸­åŒ…å« reasoning_content å­—æ®µ
{
  "choices": [{
    "delta": {
      "reasoning_content": "Let me think about this step by step...",
      "content": "The answer is..."
    }
  }]
}

// å¯é€‰è½¬æ¢ä¸º<think>æ ‡ç­¾ï¼ˆå…¼å®¹æ€§ï¼‰
if info.ThinkingToContent {
    convertedContent := fmt.Sprintf("<think>\n%s\n</think>\n%s",
        delta.ReasoningContent,
        delta.Content,
    )
}
```

**Non-Streamingæ¨¡å¼**:

```go
// å®Œæ•´å“åº”åŒ…å« reasoning_content
{
  "choices": [{
    "message": {
      "reasoning_content": "My reasoning process...",
      "content": "Final answer..."
    }
  }]
}
```

### 2. ç¼“å­˜è®¡è´¹ï¼ˆCache Billingï¼‰

æ”¯æŒå¤šå®¶å‚å•†çš„ç¼“å­˜æœºåˆ¶ï¼Œä¼˜åŒ–æˆæœ¬ã€‚

**æ”¯æŒçš„å‚å•†**:
- Azure OpenAI
- DeepSeek
- Qwen (é€šä¹‰åƒé—®)

**ä½¿ç”¨ç»Ÿè®¡ç»“æ„**:

```go
type Usage struct {
    PromptTokens        int               `json:"prompt_tokens"`
    CompletionTokens    int               `json:"completion_tokens"`
    TotalTokens         int               `json:"total_tokens"`
    
    // ç¼“å­˜ç›¸å…³
    PromptTokensDetails *PromptTokensDetails `json:"prompt_tokens_details,omitempty"`
}

type PromptTokensDetails struct {
    CachedTokens    int `json:"cached_tokens"`     // ç¼“å­˜å‘½ä¸­Tokenæ•°
    AudioTokens     int `json:"audio_tokens"`      // éŸ³é¢‘Tokenæ•°
}
```

**å¤„ç†é€»è¾‘**:

```go
// å…¼å®¹ä¸åŒå‚å•†çš„å­—æ®µå
if usage.PromptTokensDetails != nil {
    // Azure/OpenAI: cached_tokens
    cachedTokens := usage.PromptTokensDetails.CachedTokens
    
    // DeepSeek/Qwen: prompt_cache_hit_tokens
    if cachedTokens == 0 && usage.PromptCacheHitTokens > 0 {
        cachedTokens = usage.PromptCacheHitTokens
    }
    
    // è®¡ç®—å®é™…è®¡è´¹Token
    billablePromptTokens := usage.PromptTokens - cachedTokens
    
    // ç¼“å­˜å‘½ä¸­è®¡è´¹ï¼ˆé€šå¸¸æ˜¯æ­£å¸¸ä»·æ ¼çš„10%ï¼‰
    cacheCost := cachedTokens * 0.1 * promptPrice
    normalCost := billablePromptTokens * promptPrice
    
    totalCost := cacheCost + normalCost
}
```

### 3. å¤šæ ¼å¼è½¬æ¢

æ”¯æŒå®¢æˆ·ç«¯ä½¿ç”¨ä»»æ„æ ¼å¼ï¼ˆOpenAI/Claude/Geminiï¼‰ï¼ŒæœåŠ¡ç«¯è‡ªåŠ¨è½¬æ¢ã€‚

#### 3.1 Claude â†’ OpenAI è½¬æ¢

**æ–‡ä»¶**: `service/convert.go`

```go
func ClaudeToOpenAIRequest(claudeReq dto.ClaudeRequest, info *RelayInfo) (*dto.GeneralOpenAIRequest, error) {
    openaiReq := &dto.GeneralOpenAIRequest{
        Model:       claudeReq.Model,
        MaxTokens:   claudeReq.MaxTokens,
        Temperature: claudeReq.Temperature,
        TopP:        claudeReq.TopP,
        Stream:      claudeReq.Stream,
    }
    
    // 1. System prompt è½¬æ¢
    if claudeReq.System != "" {
        openaiReq.Messages = append(openaiReq.Messages, dto.Message{
            Role:    "system",
            Content: claudeReq.System,
        })
    }
    
    // 2. Messages è½¬æ¢
    for _, msg := range claudeReq.Messages {
        openaiMsg := dto.Message{
            Role: msg.Role,
        }
        
        // å†…å®¹æ ¼å¼è½¬æ¢ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
        if len(msg.Content) > 0 {
            // Claude å¤šæ¨¡æ€æ ¼å¼ â†’ OpenAI æ ¼å¼
            for _, content := range msg.Content {
                switch content.Type {
                case "text":
                    openaiMsg.Content += content.Text
                    
                case "image":
                    // å›¾ç‰‡è½¬æ¢
                    openaiMsg.MultiContent = append(openaiMsg.MultiContent, dto.Content{
                        Type: "image_url",
                        ImageURL: &dto.ImageURL{
                            URL: fmt.Sprintf("data:%s;base64,%s",
                                content.Source.MediaType,
                                content.Source.Data,
                            ),
                        },
                    })
                    
                case "thinking":
                    // Claudeçš„thinkingå—è½¬æ¢
                    openaiMsg.Content += fmt.Sprintf("<think>%s</think>", content.Text)
                }
            }
        } else {
            openaiMsg.Content = msg.StringContent
        }
        
        openaiReq.Messages = append(openaiReq.Messages, openaiMsg)
    }
    
    // 3. Tool calls è½¬æ¢
    if len(claudeReq.Tools) > 0 {
        for _, tool := range claudeReq.Tools {
            openaiReq.Tools = append(openaiReq.Tools, dto.Tool{
                Type: "function",
                Function: dto.Function{
                    Name:        tool.Name,
                    Description: tool.Description,
                    Parameters:  tool.InputSchema,
                },
            })
        }
    }
    
    return openaiReq, nil
}
```

#### 3.2 OpenAI â†’ Claude è½¬æ¢

```go
func ResponseOpenAI2Claude(openaiResp *dto.OpenAITextResponse, info *RelayInfo) *dto.ClaudeResponse {
    claudeResp := &dto.ClaudeResponse{
        ID:      openaiResp.ID,
        Type:    "message",
        Role:    "assistant",
        Model:   openaiResp.Model,
        Content: []dto.ClaudeContent{},
    }
    
    // è½¬æ¢choices â†’ content
    if len(openaiResp.Choices) > 0 {
        choice := openaiResp.Choices[0]
        
        // 1. æ–‡æœ¬å†…å®¹
        if choice.Message.Content != "" {
            claudeResp.Content = append(claudeResp.Content, dto.ClaudeContent{
                Type: "text",
                Text: choice.Message.Content,
            })
        }
        
        // 2. æ¨ç†å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if choice.Message.ReasoningContent != "" {
            claudeResp.Content = append(claudeResp.Content, dto.ClaudeContent{
                Type: "thinking",
                Text: choice.Message.ReasoningContent,
            })
        }
        
        // 3. å·¥å…·è°ƒç”¨
        for _, toolCall := range choice.Message.ToolCalls {
            claudeResp.Content = append(claudeResp.Content, dto.ClaudeContent{
                Type: "tool_use",
                ID:   toolCall.ID,
                Name: toolCall.Function.Name,
                Input: parseJSON(toolCall.Function.Arguments),
            })
        }
        
        // 4. Stop reasonæ˜ å°„
        stopReasonMap := map[string]string{
            "stop":         "end_turn",
            "length":       "max_tokens",
            "tool_calls":   "tool_use",
            "content_filter": "stop_sequence",
        }
        claudeResp.StopReason = stopReasonMap[choice.FinishReason]
    }
    
    // è½¬æ¢Usage
    if openaiResp.Usage != nil {
        claudeResp.Usage = dto.ClaudeUsage{
            InputTokens:  openaiResp.Usage.PromptTokens,
            OutputTokens: openaiResp.Usage.CompletionTokens,
        }
    }
    
    return claudeResp
}
```

### 4. Token è®¡æ•°ï¼ˆç²¾ç¡®è®¡è´¹ï¼‰

**æ–‡ä»¶**: `service/token_counter.go`

ä½¿ç”¨ tiktoken åº“è¿›è¡Œç²¾ç¡®Tokenè®¡æ•°ã€‚

```go
import "github.com/pkoukk/tiktoken-go"

// æ¨¡å‹å¯¹åº”çš„ç¼–ç å™¨
var encoderMap = map[string]string{
    "gpt-4":          "cl100k_base",
    "gpt-4-turbo":    "cl100k_base",
    "gpt-3.5-turbo":  "cl100k_base",
    "text-embedding": "cl100k_base",
    "davinci":        "p50k_base",
}

func CountTokens(model string, text string) int {
    encoding := encoderMap[model]
    if encoding == "" {
        encoding = "cl100k_base" // é»˜è®¤
    }
    
    tke, err := tiktoken.GetEncoding(encoding)
    if err != nil {
        // é™çº§åˆ°ä¼°ç®—ï¼ˆ1 token â‰ˆ 4 charsï¼‰
        return len(text) / 4
    }
    
    tokens := tke.Encode(text, nil, nil)
    return len(tokens)
}

// æ¶ˆæ¯Tokenè®¡æ•°ï¼ˆåŒ…å«æ ¼å¼å¼€é”€ï¼‰
func CountMessageTokens(model string, messages []dto.Message) int {
    totalTokens := 0
    
    // æ¯æ¡æ¶ˆæ¯çš„å›ºå®šå¼€é”€ï¼ˆ<|start|>role<|message|>content<|end|>ï¼‰
    messageOverhead := 4
    
    for _, msg := range messages {
        totalTokens += messageOverhead
        totalTokens += CountTokens(model, msg.Role)
        totalTokens += CountTokens(model, msg.Content)
        
        // å¤šæ¨¡æ€å†…å®¹
        for _, content := range msg.MultiContent {
            if content.Type == "text" {
                totalTokens += CountTokens(model, content.Text)
            } else if content.Type == "image_url" {
                // å›¾ç‰‡Tokenè®¡ç®—ï¼ˆåŸºäºå›¾ç‰‡å°ºå¯¸ï¼‰
                totalTokens += CalculateImageTokens(content.ImageURL.URL)
            }
        }
        
        // å·¥å…·è°ƒç”¨
        for _, toolCall := range msg.ToolCalls {
            totalTokens += CountTokens(model, toolCall.Function.Name)
            totalTokens += CountTokens(model, toolCall.Function.Arguments)
        }
    }
    
    // è¡¥å…¨å¼€å§‹æ ‡è®°
    totalTokens += 3
    
    return totalTokens
}

// å›¾ç‰‡Tokenè®¡ç®—
func CalculateImageTokens(imageURL string) int {
    // OpenAI å›¾ç‰‡Tokenè®¡ç®—è§„åˆ™:
    // - ä½åˆ†è¾¨ç‡: 85 tokens
    // - é«˜åˆ†è¾¨ç‡: 170 tokens + é¢å¤–tile tokens
    // 
    // Tileè®¡ç®—: ceil(width/512) * ceil(height/512) * 170
    
    // ç®€åŒ–ç‰ˆæœ¬ï¼ˆå‡è®¾é«˜åˆ†è¾¨ç‡ï¼‰
    return 765 // (512x512 â†’ 2x2 tiles = 4*170 + 85)
}
```

---

## ğŸ”€ å¤šæ¸ é“æ”¯æŒ

### 1. æ¸ é“ç®¡ç†æ¶æ„

**æ•°æ®æ¨¡å‹**:

**æ–‡ä»¶**: `model/channel.go`

```go
type Channel struct {
    Id              int       `json:"id"`
    Type            int       `json:"type"`           // æ¸ é“ç±»å‹ï¼ˆOpenAI/Azure/Claudeç­‰ï¼‰
    Key             string    `json:"key"`            // APIå¯†é’¥ï¼ˆåŠ å¯†å­˜å‚¨ï¼‰
    BaseURL         string    `json:"base_url"`       // è‡ªå®šä¹‰ç«¯ç‚¹
    Models          string    `json:"models"`         // æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰
    Priority        int       `json:"priority"`       // ä¼˜å…ˆçº§ï¼ˆç”¨äºåŠ æƒé€‰æ‹©ï¼‰
    Weight          int       `json:"weight"`         // æƒé‡
    Status          int       `json:"status"`         // çŠ¶æ€ï¼ˆ1=å¯ç”¨ 2=ç¦ç”¨ 3=è‡ªåŠ¨ç¦ç”¨ï¼‰
    
    // ç»Ÿè®¡ä¿¡æ¯
    SuccessCount    int       `json:"success_count"`  // æˆåŠŸè¯·æ±‚æ•°
    FailureCount    int       `json:"failure_count"`  // å¤±è´¥è¯·æ±‚æ•°
    LastUsedTime    int64     `json:"last_used_time"` // æœ€åä½¿ç”¨æ—¶é—´
    
    // é…ç½®
    Config          string    `json:"config"`         // JSONæ ¼å¼çš„æ¸ é“ç‰¹å®šé…ç½®
    
    CreatedTime     int64     `json:"created_time"`
    TestTime        int64     `json:"test_time"`      // æœ€åæµ‹è¯•æ—¶é—´
}
```

### 2. æ¸ é“é€‰æ‹©ç­–ç•¥

**æ–‡ä»¶**: `middleware/distributor.go`

```go
func selectChannel(c *gin.Context, modelName string) (*model.Channel, error) {
    // 1. è·å–å¯ç”¨æ¸ é“åˆ—è¡¨
    channels, err := model.GetEnabledChannelsByModel(modelName)
    if err != nil || len(channels) == 0 {
        return nil, errors.New("no available channels")
    }
    
    // 2. è¿‡æ»¤å¥åº·çš„æ¸ é“
    healthyChannels := []model.Channel{}
    for _, ch := range channels {
        if isChannelHealthy(&ch) {
            healthyChannels = append(healthyChannels, ch)
        }
    }
    
    if len(healthyChannels) == 0 {
        // é™çº§: å°è¯•ä½¿ç”¨çŠ¶æ€ä¸ä½³çš„æ¸ é“
        healthyChannels = channels
    }
    
    // 3. åŠ æƒéšæœºé€‰æ‹©
    channel := weightedRandomSelect(healthyChannels)
    
    return channel, nil
}

// å¥åº·æ£€æŸ¥
func isChannelHealthy(channel *model.Channel) bool {
    // å¤±è´¥ç‡é˜ˆå€¼æ£€æŸ¥
    totalRequests := channel.SuccessCount + channel.FailureCount
    if totalRequests > 10 {
        failureRate := float64(channel.FailureCount) / float64(totalRequests)
        if failureRate > 0.5 { // å¤±è´¥ç‡è¶…è¿‡50%
            return false
        }
    }
    
    // è¿ç»­å¤±è´¥æ£€æŸ¥
    if channel.FailureCount > 5 {
        // æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰æˆåŠŸ
        timeSinceLastSuccess := time.Now().Unix() - channel.LastUsedTime
        if timeSinceLastSuccess > 300 { // 5åˆ†é’Ÿå†…æ²¡æœ‰æˆåŠŸ
            return false
        }
    }
    
    return true
}

// åŠ æƒéšæœºé€‰æ‹©
func weightedRandomSelect(channels []model.Channel) *model.Channel {
    // è®¡ç®—æ€»æƒé‡
    totalWeight := 0
    for _, ch := range channels {
        weight := ch.Priority // æˆ–ä½¿ç”¨ ch.Weight
        if weight <= 0 {
            weight = 1
        }
        totalWeight += weight
    }
    
    // éšæœºé€‰æ‹©
    randValue := rand.Intn(totalWeight)
    currentWeight := 0
    
    for i, ch := range channels {
        weight := ch.Priority
        if weight <= 0 {
            weight = 1
        }
        currentWeight += weight
        
        if randValue < currentWeight {
            return &channels[i]
        }
    }
    
    return &channels[0] // é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ª
}
```

### 3. è‡ªåŠ¨æ•…éšœè½¬ç§»

**æ–‡ä»¶**: `controller/relay.go`

```go
func relayWithFailover(c *gin.Context, info *relaycommon.RelayInfo, request *dto.GeneralOpenAIRequest) (*dto.Usage, *types.NewAPIError) {
    maxFailoverAttempts := 3
    originalChannelId := info.ChannelId
    
    for attempt := 0; attempt < maxFailoverAttempts; attempt++ {
        // æ‰§è¡Œè¯·æ±‚
        usage, err := relayHandler(c, info, request)
        
        if err == nil {
            // æˆåŠŸ: æ›´æ–°æ¸ é“ç»Ÿè®¡
            model.UpdateChannelSuccess(info.ChannelId)
            return usage, nil
        }
        
        // å¤±è´¥: è®°å½•å¹¶å°è¯•åˆ‡æ¢æ¸ é“
        logger.Error(c, fmt.Sprintf("Channel %d failed: %s", info.ChannelId, err.Message))
        model.UpdateChannelFailure(info.ChannelId)
        
        // åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ‡æ¢æ¸ é“
        if !shouldFailover(err) {
            return nil, err
        }
        
        // é€‰æ‹©æ–°æ¸ é“
        newChannel, failoverErr := selectChannel(c, info.OriginModelName)
        if failoverErr != nil {
            return nil, err // è¿”å›åŸå§‹é”™è¯¯
        }
        
        // é¿å…é‡å¤é€‰æ‹©åŒä¸€æ¸ é“
        if newChannel.Id == originalChannelId && attempt < maxFailoverAttempts-1 {
            continue
        }
        
        // æ›´æ–°RelayInfo
        info.ChannelId = newChannel.Id
        info.ChannelType = newChannel.Type
        info.ApiKey = newChannel.Key
        info.ChannelBaseUrl = newChannel.BaseURL
        
        logger.Info(c, fmt.Sprintf("Failover to channel %d (attempt %d)", newChannel.Id, attempt+1))
    }
    
    return nil, types.NewAPIError(503, "All channels failed")
}

// åˆ¤æ–­æ˜¯å¦åº”è¯¥æ•…éšœè½¬ç§»
func shouldFailover(err *types.NewAPIError) bool {
    // å¯é‡è¯•çš„é”™è¯¯ç 
    failoverStatusCodes := []int{
        429,  // Rate limit
        500,  // Internal server error
        502,  // Bad gateway
        503,  // Service unavailable
        504,  // Gateway timeout
    }
    
    for _, code := range failoverStatusCodes {
        if err.StatusCode == code {
            return true
        }
    }
    
    return false
}
```

### 4. æ¸ é“ç‰¹å®šé…ç½®

ä¸åŒæ¸ é“å¯ä»¥æœ‰è‡ªå®šä¹‰é…ç½®ã€‚

**é…ç½®ç»“æ„** (`dto/channel_settings.go`):

```go
type ChannelSettings struct {
    // é€šç”¨é…ç½®
    ForceFormat         bool   `json:"force_format"`          // å¼ºåˆ¶å“åº”æ ¼å¼
    ThinkingToContent   bool   `json:"thinking_to_content"`   // æ¨ç†å†…å®¹è½¬æ¢
    
    // Azureç‰¹å®š
    ApiVersion          string `json:"api_version"`           // Azure APIç‰ˆæœ¬
    
    // å‚æ•°è¦†ç›–
    MaxTokens           int    `json:"max_tokens"`            // è¦†ç›–max_tokens
    Temperature         float64 `json:"temperature"`          // è¦†ç›–temperature
    
    // è‡ªå®šä¹‰å¤´
    CustomHeaders       map[string]string `json:"custom_headers"` // é¢å¤–HTTPå¤´
    
    // è¶…æ—¶é…ç½®
    Timeout             int    `json:"timeout"`               // è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
    
    // æ¨¡å‹æ˜ å°„
    ModelMapping        map[string]string `json:"model_mapping"` // æ¨¡å‹åæ˜ å°„
}
```

**åº”ç”¨é…ç½®**:

```go
// ä»æ¸ é“é…ç½®JSONè§£æ
var settings dto.ChannelSettings
json.Unmarshal([]byte(channel.Config), &settings)

// åº”ç”¨é…ç½®
if settings.ForceFormat {
    info.ResponseFormat = "openai"
}

if settings.ThinkingToContent {
    info.ThinkingToContent = true
}

// æ¨¡å‹åæ˜ å°„
if mappedModel, ok := settings.ModelMapping[info.OriginModelName]; ok {
    info.UpstreamModelName = mappedModel
}

// è‡ªå®šä¹‰è¶…æ—¶
if settings.Timeout > 0 {
    info.Timeout = settings.Timeout
}
```

---

## ğŸ“Š å®Œæ•´è°ƒç”¨æµç¨‹ç¤ºä¾‹

### åœºæ™¯ï¼šå®¢æˆ·ç«¯è°ƒç”¨ Chat Completions API

#### 1. å®¢æˆ·ç«¯è¯·æ±‚

```bash
curl https://api.your-gateway.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-xxxxxxxxxxxxx" \
  -d '{
    "model": "gpt-4",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is 2+2?"}
    ],
    "stream": true
  }'
```

#### 2. è·¯ç”±å±‚å¤„ç†

```
POST /v1/chat/completions
  â†“
router.POST("/chat/completions", func(c *gin.Context) {
    controller.Relay(c, types.RelayFormatOpenAI)
})
```

#### 3. ä¸­é—´ä»¶å¤„ç†

##### A. CORSä¸­é—´ä»¶
```go
// å…è®¸è·¨åŸŸè¯·æ±‚
c.Header("Access-Control-Allow-Origin", "*")
```

##### B. TokenAuthä¸­é—´ä»¶
```go
// 1. æå–Token: "Bearer sk-xxxxxxxxxxxxx"
token := extractToken(c)

// 2. æ•°æ®åº“éªŒè¯
dbToken := model.ValidateUserToken(token)
if dbToken == nil {
    c.JSON(401, gin.H{"error": "Invalid token"})
    return
}

// 3. æ£€æŸ¥é…é¢
if dbToken.RemainQuota <= 0 {
    c.JSON(429, gin.H{"error": "Quota exceeded"})
    return
}

// 4. è®¾ç½®ä¸Šä¸‹æ–‡
c.Set("token_id", dbToken.Id)
c.Set("user_id", dbToken.UserId)
c.Set("remain_quota", dbToken.RemainQuota)
```

##### C. RateLimitä¸­é—´ä»¶
```go
// é™æµæ£€æŸ¥
if isRateLimited(dbToken.UserId, "gpt-4") {
    c.JSON(429, gin.H{"error": "Rate limit exceeded"})
    return
}
```

##### D. Distributeä¸­é—´ä»¶
```go
// é€‰æ‹©æ¸ é“
channels := model.GetEnabledChannelsByModel("gpt-4")
// å‡è®¾æœ‰3ä¸ªOpenAIæ¸ é“:
// - Channel 1: Priority 10, BaseURL: api.openai.com
// - Channel 2: Priority 5,  BaseURL: api.openai.com (å¤‡ç”¨)
// - Channel 3: Priority 2,  BaseURL: custom-proxy.com

// åŠ æƒéšæœºé€‰æ‹© â†’ é€‰ä¸­ Channel 1
selectedChannel := weightedRandomSelect(channels)

c.Set("channel", selectedChannel)
```

#### 4. æ§åˆ¶å™¨å¤„ç†

```go
func Relay(c *gin.Context, relayFormat types.RelayFormat) {
    // 1. è§£æè¯·æ±‚ä½“
    var request dto.GeneralOpenAIRequest
    c.ShouldBindJSON(&request)
    // request.Model = "gpt-4"
    // request.Messages = [...]
    // request.Stream = true
    
    // 2. è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
    tokenId := c.GetInt("token_id")
    userId := c.GetInt("user_id")
    channel := c.MustGet("channel").(model.Channel)
    
    // 3. æ„å»ºRelayInfo
    info := &relaycommon.RelayInfo{
        TokenId:           tokenId,
        UserId:            userId,
        ChannelId:         channel.Id,
        ChannelType:       channel.Type,      // constant.ChannelTypeOpenAI
        ApiKey:            channel.Key,        // sk-xxxxxxxxxxxxxxx
        ChannelBaseUrl:    channel.BaseURL,   // https://api.openai.com
        OriginModelName:   "gpt-4",
        UpstreamModelName: "gpt-4",
        IsStream:          true,
        RelayMode:         constant.RelayModeChatCompletions,
    }
    
    // 4. è°ƒç”¨relayå¤„ç†
    usage, err := relayHandler(c, info, &request)
    
    // 5. æ‰£é™¤é…é¢ï¼ˆè¯·æ±‚ç»“æŸåï¼‰
    if err == nil {
        cost := calculateCost(usage, "gpt-4")
        model.DeductQuota(tokenId, cost)
    }
    
    // 6. è®°å½•æ—¥å¿—
    logRequest(info, usage, err)
}
```

#### 5. Relay Handlerå¤„ç†

```go
func relayHandler(c *gin.Context, info *relaycommon.RelayInfo, request *dto.GeneralOpenAIRequest) (*dto.Usage, *types.NewAPIError) {
    // 1. è·å–é€‚é…å™¨
    adaptor := relay.GetAdaptor(info.ChannelType)
    // â†’ è¿”å› &openai.Adaptor{}
    
    // 2. åˆå§‹åŒ–é€‚é…å™¨
    adaptor.Init(info)
    // â†’ adaptor.ChannelType = constant.ChannelTypeOpenAI
    
    // 3. è½¬æ¢è¯·æ±‚
    err := adaptor.ConvertOpenAIRequest(c, info, request)
    // â†’ æ·»åŠ  stream_options.include_usage = true
    // â†’ è®¡ç®— prompt tokens
    
    // 4. åºåˆ—åŒ–è¯·æ±‚ä½“
    requestBody, _ := json.Marshal(request)
    
    // 5. æ‰§è¡ŒHTTPè¯·æ±‚
    resp, err := adaptor.DoRequest(c, info, bytes.NewReader(requestBody))
    // â†’ URL: https://api.openai.com/v1/chat/completions
    // â†’ Header: Authorization: Bearer sk-xxxxxxx
    // â†’ Body: {"model":"gpt-4","messages":[...],"stream":true,...}
    
    if err != nil {
        return nil, types.NewAPIError(500, err.Error())
    }
    
    // 6. å¤„ç†å“åº”
    usage, apiErr := adaptor.DoResponse(c, resp, info)
    // â†’ è°ƒç”¨ OaiStreamHandler (å› ä¸º IsStream=true)
    
    return usage, apiErr
}
```

#### 6. OpenAI Adaptorå¤„ç†

##### A. DoRequestæ‰§è¡Œ

```go
func (a *Adaptor) DoRequest(c *gin.Context, info *relaycommon.RelayInfo, requestBody io.Reader) (*http.Response, error) {
    // 1. æ„å»ºURL
    fullRequestURL, _ := a.GetRequestURL(info)
    // â†’ "https://api.openai.com/v1/chat/completions"
    
    // 2. åˆ›å»ºHTTPè¯·æ±‚
    req, _ := http.NewRequest("POST", fullRequestURL, requestBody)
    
    // 3. è®¾ç½®è¯·æ±‚å¤´
    a.SetupRequestHeader(c, &req.Header, info)
    // â†’ Authorization: Bearer sk-xxxxxxx
    // â†’ Content-Type: application/json
    
    // 4. æ‰§è¡Œè¯·æ±‚
    client := &http.Client{Timeout: 180 * time.Second}
    resp, err := client.Do(req)
    
    return resp, err
}
```

##### B. DoResponseå¤„ç†ï¼ˆæµå¼ï¼‰

```go
func (a *Adaptor) DoResponse(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo) (*dto.Usage, *types.NewAPIError) {
    // å› ä¸º IsStream=trueï¼Œè·¯ç”±åˆ° OaiStreamHandler
    return OaiStreamHandler(c, resp, info, a.ResponseFormat)
}
```

#### 7. æµå¼å“åº”å¤„ç†

```go
func OaiStreamHandler(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo, responseFormat string) (*dto.Usage, *types.NewAPIError) {
    // 1. è®¾ç½®SSEå“åº”å¤´
    c.Header("Content-Type", "text/event-stream")
    c.Header("Cache-Control", "no-cache")
    c.Header("Connection", "keep-alive")
    
    // 2. åˆå§‹åŒ–usage
    usage := &dto.Usage{}
    
    // 3. é€è¡Œè¯»å–SSEæµ
    scanner := bufio.NewScanner(resp.Body)
    for scanner.Scan() {
        line := scanner.Text()
        
        if strings.HasPrefix(line, "data: ") {
            data := strings.TrimPrefix(line, "data: ")
            
            if data == "[DONE]" {
                c.Writer.Write([]byte("data: [DONE]\n\n"))
                c.Writer.Flush()
                break
            }
            
            // 4. è§£æchunk
            var chunk dto.ChatCompletionsStreamResponse
            json.Unmarshal([]byte(data), &chunk)
            // chunk = {
            //   "id": "chatcmpl-xxxxx",
            //   "choices": [{
            //     "delta": {"content": "4"},
            //     "index": 0
            //   }]
            // }
            
            // 5. ç´¯åŠ tokenè®¡æ•°
            if len(chunk.Choices) > 0 {
                delta := chunk.Choices[0].Delta
                if delta.Content != "" {
                    usage.CompletionTokens += countTokens(delta.Content)
                }
            }
            
            // 6. æå–æœ€ç»ˆusageï¼ˆæœ€åä¸€ä¸ªchunkï¼‰
            if chunk.Usage != nil {
                usage.PromptTokens = chunk.Usage.PromptTokens
                usage.CompletionTokens = chunk.Usage.CompletionTokens
                usage.TotalTokens = chunk.Usage.TotalTokens
            }
            
            // 7. è½¬å‘ç»™å®¢æˆ·ç«¯
            c.Writer.Write([]byte("data: " + data + "\n\n"))
            c.Writer.Flush()
        }
    }
    
    // 8. è¿”å›usageç”¨äºè®¡è´¹
    return usage, nil
}
```

#### 8. å®¢æˆ·ç«¯æ¥æ”¶å“åº”

```
data: {"id":"chatcmpl-xxxxx","choices":[{"delta":{"role":"assistant"},"index":0}]}

data: {"id":"chatcmpl-xxxxx","choices":[{"delta":{"content":"The"},"index":0}]}

data: {"id":"chatcmpl-xxxxx","choices":[{"delta":{"content":" answer"},"index":0}]}

data: {"id":"chatcmpl-xxxxx","choices":[{"delta":{"content":" is"},"index":0}]}

data: {"id":"chatcmpl-xxxxx","choices":[{"delta":{"content":" 4"},"index":0}]}

data: {"id":"chatcmpl-xxxxx","choices":[{"delta":{},"index":0,"finish_reason":"stop"}],"usage":{"prompt_tokens":25,"completion_tokens":5,"total_tokens":30}}

data: [DONE]
```

#### 9. è®¡è´¹ä¸æ—¥å¿—

```go
// è®¡ç®—æˆæœ¬
// GPT-4 ä»·æ ¼: $0.03 / 1K prompt tokens, $0.06 / 1K completion tokens
promptCost := (usage.PromptTokens / 1000.0) * 0.03
completionCost := (usage.CompletionTokens / 1000.0) * 0.06
totalCost := promptCost + completionCost

// æ‰£é™¤é…é¢
model.DeductQuota(tokenId, totalCost)

// è®°å½•æ—¥å¿—
model.CreateLog(&model.Log{
    UserId:           userId,
    ChannelId:        channelId,
    TokenId:          tokenId,
    Model:            "gpt-4",
    PromptTokens:     usage.PromptTokens,
    CompletionTokens: usage.CompletionTokens,
    Cost:             totalCost,
    CreatedAt:        time.Now().Unix(),
})
```

---

## âš™ï¸ é…ç½®ä¸éƒ¨ç½²

### 1. ç¯å¢ƒå˜é‡é…ç½®

**æ–‡ä»¶**: `.env`

```bash
# æ•°æ®åº“é…ç½®
DB_TYPE=mysql
DB_HOST=localhost
DB_PORT=3306
DB_NAME=new_api
DB_USER=root
DB_PASSWORD=password

# Redisé…ç½®ï¼ˆå¯é€‰ï¼Œç”¨äºç¼“å­˜å’Œé™æµï¼‰
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# æœåŠ¡é…ç½®
PORT=3000
GIN_MODE=release

# æ—¥å¿—é…ç½®
LOG_LEVEL=info
LOG_DIR=./logs

# å®‰å…¨é…ç½®
SESSION_SECRET=your-secret-key-here
API_KEY_SALT=your-salt-here
```

### 2. æ¸ é“é…ç½®ç¤ºä¾‹

**é€šè¿‡ç®¡ç†ç•Œé¢æˆ–APIé…ç½®æ¸ é“**:

#### OpenAIå®˜æ–¹æ¸ é“

```json
{
  "type": 1,
  "name": "OpenAI Official",
  "base_url": "https://api.openai.com",
  "key": "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
  "models": "gpt-4,gpt-4-turbo,gpt-3.5-turbo,text-embedding-ada-002",
  "priority": 10,
  "status": 1,
  "config": {
    "force_format": false,
    "thinking_to_content": false,
    "timeout": 180
  }
}
```

#### Azure OpenAIæ¸ é“

```json
{
  "type": 8,
  "name": "Azure OpenAI",
  "base_url": "https://your-resource.openai.azure.com",
  "key": "your-azure-api-key",
  "models": "gpt-4,gpt-35-turbo",
  "priority": 8,
  "status": 1,
  "config": {
    "api_version": "2024-02-15-preview",
    "model_mapping": {
      "gpt-4": "gpt-4-deployment-name",
      "gpt-3.5-turbo": "gpt-35-turbo-deployment"
    }
  }
}
```

#### è‡ªå®šä¹‰OpenAIå…¼å®¹æ¸ é“

```json
{
  "type": 1,
  "name": "Custom Proxy",
  "base_url": "https://custom-proxy.com/v1",
  "key": "custom-api-key",
  "models": "gpt-4,gpt-3.5-turbo",
  "priority": 5,
  "status": 1,
  "config": {
    "custom_headers": {
      "X-Custom-Header": "value"
    }
  }
}
```

### 3. æ•°æ®åº“Schema

**æ¸ é“è¡¨** (`channels`):

```sql
CREATE TABLE `channels` (
  `id` int NOT NULL AUTO_INCREMENT,
  `type` int NOT NULL,
  `name` varchar(255) NOT NULL,
  `key` text NOT NULL,
  `base_url` varchar(255) DEFAULT NULL,
  `models` text,
  `priority` int DEFAULT '0',
  `weight` int DEFAULT '0',
  `status` int DEFAULT '1',
  `success_count` int DEFAULT '0',
  `failure_count` int DEFAULT '0',
  `last_used_time` bigint DEFAULT NULL,
  `config` text,
  `created_time` bigint NOT NULL,
  `test_time` bigint DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `idx_type` (`type`),
  KEY `idx_status` (`status`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

**Tokenè¡¨** (`tokens`):

```sql
CREATE TABLE `tokens` (
  `id` int NOT NULL AUTO_INCREMENT,
  `user_id` int NOT NULL,
  `key` varchar(48) NOT NULL UNIQUE,
  `name` varchar(255) DEFAULT NULL,
  `remain_quota` bigint DEFAULT '0',
  `unlimited_quota` tinyint(1) DEFAULT '0',
  `status` int DEFAULT '1',
  `created_time` bigint NOT NULL,
  `accessed_time` bigint DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_key` (`key`),
  KEY `idx_user_id` (`user_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

### 4. éƒ¨ç½²æ–¹å¼

#### A. Dockeréƒ¨ç½²

```bash
# ä½¿ç”¨å®˜æ–¹é•œåƒ
docker run -d \
  --name new-api \
  -p 3000:3000 \
  -e DB_TYPE=mysql \
  -e DB_HOST=your-db-host \
  -e DB_USER=root \
  -e DB_PASSWORD=password \
  -e DB_NAME=new_api \
  calciumion/new-api:latest

# ä½¿ç”¨docker-compose
docker-compose up -d
```

#### B. æºç éƒ¨ç½²

```bash
# å®‰è£…ä¾èµ–
go mod download

# ç¼–è¯‘
go build -o new-api main.go

# è¿è¡Œ
./new-api
```

#### C. SystemdæœåŠ¡

```ini
[Unit]
Description=New API Service
After=network.target

[Service]
Type=simple
User=www-data
WorkingDirectory=/opt/new-api
ExecStart=/opt/new-api/new-api
Restart=on-failure

[Install]
WantedBy=multi-user.target
```

---

## ğŸ“š å‚è€ƒèµ„æº

- [OpenAI API Official Documentation](https://platform.openai.com/docs/api-reference)
- [Azure OpenAI Documentation](https://learn.microsoft.com/azure/ai-services/openai/)
- [New-API GitHub Repository](https://github.com/Calcium-Ion/new-api)
- [Tiktoken - OpenAI Tokenizer](https://github.com/openai/tiktoken)

---

## ğŸ“ æ€»ç»“

### OpenAI é›†æˆæ ¸å¿ƒè¦ç‚¹

1. **é€‚é…å™¨æ¨¡å¼**: ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒå¤šç§è¡ç”ŸæœåŠ¡ï¼ˆOpenAI/Azure/OpenRouterï¼‰
2. **å¤šæ ¼å¼å…¼å®¹**: è‡ªåŠ¨è¯†åˆ«å¹¶è½¬æ¢ OpenAI/Claude/Gemini æ ¼å¼
3. **æ¨ç†æ¨¡å‹æ”¯æŒ**: å®Œæ•´æ”¯æŒ Oç³»åˆ—æ¨ç†æ¨¡å‹çš„ç‰¹æ®ŠåŠŸèƒ½
4. **æµå¼å¤„ç†**: é«˜æ•ˆçš„ SSE æµå¼å“åº”å’Œ WebSocket å®æ—¶é€šä¿¡
5. **å¤šæ¸ é“æ¶æ„**: è´Ÿè½½å‡è¡¡ã€æ•…éšœè½¬ç§»ã€å¥åº·æ£€æŸ¥
6. **ç²¾ç¡®è®¡è´¹**: åŸºäº tiktoken çš„ç²¾ç¡® Token è®¡æ•°
7. **ä¼ä¸šçº§åŠŸèƒ½**: é…é¢ç®¡ç†ã€å¤šç§Ÿæˆ·ã€å®¡è®¡æ—¥å¿—

### æ¶æ„ä¼˜åŠ¿

âœ… **é«˜å¯ç”¨æ€§**: å¤šæ¸ é“å†—ä½™ + è‡ªåŠ¨æ•…éšœè½¬ç§»  
âœ… **é«˜æ€§èƒ½**: æµå¼å¤„ç† + è¿æ¥æ± ä¼˜åŒ–  
âœ… **é«˜æ‰©å±•æ€§**: æ’ä»¶åŒ–é€‚é…å™¨æ¶æ„  
âœ… **æˆæœ¬ä¼˜åŒ–**: ç¼“å­˜è®¡è´¹ + ç²¾ç¡®Tokenè®¡æ•°  
âœ… **å¼€å‘å‹å¥½**: ç»Ÿä¸€APIæ¥å£ + å¤šæ ¼å¼å…¼å®¹

### åç»­æ‰©å±•æ–¹å‘

- æ”¯æŒæ›´å¤š OpenAI å…¼å®¹æœåŠ¡ï¼ˆAnthropicã€Google AI Studioç­‰ï¼‰
- å¢å¼ºæ¨ç†æ¨¡å‹åŠŸèƒ½ï¼ˆæ€ç»´é“¾å¯è§†åŒ–ã€æ¨ç†è¿‡ç¨‹æ§åˆ¶ï¼‰
- æ€§èƒ½ä¼˜åŒ–ï¼ˆè¯·æ±‚æ‰¹å¤„ç†ã€å“åº”ç¼“å­˜ã€è¿æ¥å¤ç”¨ï¼‰
- é«˜çº§ç›‘æ§ï¼ˆå®æ—¶metricsã€é“¾è·¯è¿½è¸ªã€æ€§èƒ½åˆ†æï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-11-25  
**è®¸å¯è¯**: MIT
