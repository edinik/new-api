# New-API è¿æ¥ Gemini è¯¦ç»†æŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> **åˆ›å»ºæ—¥æœŸ**: 2024-11-23  
> **ä½œè€…**: Snow AI  
> **é¡¹ç›®**: [New-API](https://github.com/Calcium-Ion/new-api)

---

## ğŸ“‹ ç›®å½•

- [æ¶æ„æ¦‚è§ˆ](#æ¶æ„æ¦‚è§ˆ)
- [è¿æ¥æ­¥éª¤è¯¦è§£](#è¿æ¥æ­¥éª¤è¯¦è§£)
  - [Step 1: æ¸ é“é…ç½®](#step-1-æ¸ é“é…ç½®channel-configuration)
  - [Step 2: é€‚é…å™¨åˆå§‹åŒ–](#step-2-é€‚é…å™¨åˆå§‹åŒ–adaptor-initialization)
  - [Step 3: è¯·æ±‚è½¬æ¢](#step-3-è¯·æ±‚è½¬æ¢request-conversion)
  - [Step 4: æ„å»ºè¯·æ±‚ URL](#step-4-æ„å»ºè¯·æ±‚-urlbuild-request-url)
  - [Step 5: è®¾ç½®è¯·æ±‚å¤´](#step-5-è®¾ç½®è¯·æ±‚å¤´setup-request-headers)
  - [Step 6: å‘é€è¯·æ±‚](#step-6-å‘é€è¯·æ±‚send-request)
  - [Step 7: å“åº”å¤„ç†](#step-7-å“åº”å¤„ç†response-handling)
  - [Step 8: å“åº”è½¬æ¢](#step-8-å“åº”è½¬æ¢response-conversion)
- [ç‰¹æ®ŠåŠŸèƒ½å®ç°](#ç‰¹æ®ŠåŠŸèƒ½å®ç°)
  - [æ€è€ƒæ¨¡å¼](#a-æ€è€ƒæ¨¡å¼thinking-mode)
  - [å¤šæ¨¡æ€æ”¯æŒ](#b-å¤šæ¨¡æ€æ”¯æŒ)
  - [å·¥å…·è°ƒç”¨](#c-å·¥å…·è°ƒç”¨function-calling)
  - [å®‰å…¨è®¾ç½®](#d-å®‰å…¨è®¾ç½®safety-settings)
- [å®Œæ•´è¯·æ±‚æµç¨‹å›¾](#å®Œæ•´è¯·æ±‚æµç¨‹å›¾)
- [Token è®¡è´¹é€»è¾‘](#token-è®¡è´¹é€»è¾‘)
- [é…ç½®ç¤ºä¾‹](#é…ç½®ç¤ºä¾‹)
- [æ”¯æŒçš„ Gemini æ¨¡å‹](#æ”¯æŒçš„-gemini-æ¨¡å‹)
- [æ ¸å¿ƒä¼˜åŠ¿](#æ ¸å¿ƒä¼˜åŠ¿)
- [æ€»ç»“](#æ€»ç»“)

---

## ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

New-API ä½¿ç”¨äº† **é€‚é…å™¨æ¨¡å¼ï¼ˆAdapter Patternï¼‰** æ¥ç»Ÿä¸€å¤„ç†ä¸åŒ AI æä¾›å•†çš„ APIï¼ŒGemini çš„å®ç°é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œä½äºä»¥ä¸‹ç›®å½•ç»“æ„ï¼š

```
relay/
â”œâ”€â”€ gemini_handler.go          # Gemini è¯·æ±‚å¤„ç†ä¸»å…¥å£
â”œâ”€â”€ relay_adaptor.go            # é€‚é…å™¨å·¥å‚ï¼ˆè´Ÿè´£åˆ›å»ºé€‚é…å™¨å®ä¾‹ï¼‰
â””â”€â”€ channel/gemini/             # Gemini ä¸“ç”¨å®ç°æ¨¡å—
    â”œâ”€â”€ adaptor.go              # Gemini é€‚é…å™¨æ ¸å¿ƒé€»è¾‘
    â”œâ”€â”€ relay-gemini.go         # OpenAI â†” Gemini æ ¼å¼è½¬æ¢
    â”œâ”€â”€ relay-gemini-native.go  # åŸç”Ÿ Gemini æ ¼å¼æ”¯æŒ
    â””â”€â”€ constant.go             # å¸¸é‡å®šä¹‰ï¼ˆæ¨¡å‹åˆ—è¡¨ã€å®‰å…¨è®¾ç½®ç­‰ï¼‰
```

### å…³é”®ç»„ä»¶è¯´æ˜

| ç»„ä»¶ | èŒè´£ | å…³é”®æ–¹æ³• |
|------|------|----------|
| **gemini_handler.go** | è¯·æ±‚è·¯ç”±å’Œå‰ç½®å¤„ç† | `GeminiHelper()`, `GeminiEmbeddingHandler()` |
| **adaptor.go** | å®ç°é€‚é…å™¨æ¥å£ | `ConvertOpenAIRequest()`, `DoRequest()`, `DoResponse()` |
| **relay-gemini.go** | æ ¼å¼è½¬æ¢æ ¸å¿ƒ | `CovertOpenAI2Gemini()`, `responseGeminiChat2OpenAI()` |
| **relay-gemini-native.go** | åŸç”Ÿæ ¼å¼å¤„ç† | `GeminiTextGenerationHandler()` |

---

## ğŸ”§ è¿æ¥æ­¥éª¤è¯¦è§£

### Step 1: æ¸ é“é…ç½®ï¼ˆChannel Configurationï¼‰

åœ¨ `constant/channel.go` ä¸­å®šä¹‰äº† Gemini çš„æ¸ é“ç±»å‹å’ŒåŸºç¡€é…ç½®ï¼š

```go
const (
    ChannelTypeGemini = 24  // Gemini æ¸ é“æ ‡è¯†ç¬¦ï¼ˆå”¯ä¸€ IDï¼‰
)

var ChannelBaseURLs = []string{
    // ... å…¶ä»–æ¸ é“çš„ Base URL
    "https://generativelanguage.googleapis.com", // Index 24: Gemini é»˜è®¤ API ç«¯ç‚¹
}

var ChannelTypeNames = map[int]string{
    // ...
    ChannelTypeGemini: "Gemini",
}
```

**å…³é”®é…ç½®å‚æ•°**ï¼š

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| **Base URL** | `https://generativelanguage.googleapis.com` | Gemini API çš„å®˜æ–¹ç«¯ç‚¹ |
| **API Version** | `v1beta` / `v1` | æ ¹æ®æ¨¡å‹è‡ªåŠ¨é€‰æ‹©ç‰ˆæœ¬ |
| **API Key** | é€šè¿‡è¯·æ±‚å¤´ä¼ é€’ | Header: `x-goog-api-key` |
| **Channel ID** | `24` | åœ¨æ•°æ®åº“ä¸­çš„æ¸ é“ç±»å‹æ ‡è¯† |

---

### Step 2: é€‚é…å™¨åˆå§‹åŒ–ï¼ˆAdaptor Initializationï¼‰

åœ¨ `relay/relay_adaptor.go` ä¸­ï¼Œæ ¹æ® API ç±»å‹è¿”å›å¯¹åº”çš„é€‚é…å™¨å®ä¾‹ï¼š

```go
func GetAdaptor(apiType int) Adaptor {
    switch apiType {
    case constant.APITypeOpenAI:
        return &openai.Adaptor{}
    case constant.APITypeAnthropic:
        return &claude.Adaptor{}
    case constant.APITypeGemini:
        return &gemini.Adaptor{}  // è¿”å› Gemini é€‚é…å™¨
    // ... å…¶ä»–é€‚é…å™¨
    default:
        return nil
    }
}
```

**é€‚é…å™¨æ¥å£å®šä¹‰**ï¼š

```go
type Adaptor interface {
    // è¯·æ±‚è½¬æ¢
    ConvertOpenAIRequest(c *gin.Context, info *RelayInfo, request *dto.GeneralOpenAIRequest) (any, error)
    ConvertGeminiRequest(c *gin.Context, info *RelayInfo, request *dto.GeminiChatRequest) (any, error)
    
    // HTTP è¯·æ±‚å¤„ç†
    GetRequestURL(info *RelayInfo) (string, error)
    SetupRequestHeader(c *gin.Context, req *http.Header, info *RelayInfo) error
    DoRequest(c *gin.Context, info *RelayInfo, requestBody io.Reader) (any, error)
    
    // å“åº”å¤„ç†
    DoResponse(c *gin.Context, resp *http.Response, info *RelayInfo) (usage any, err *types.NewAPIError)
    
    // å…ƒæ•°æ®
    GetModelList() []string
    GetChannelName() string
}
```

---

### Step 3: è¯·æ±‚è½¬æ¢ï¼ˆRequest Conversionï¼‰

**æ ¸å¿ƒè½¬æ¢å‡½æ•°**ï¼š`CovertOpenAI2Gemini` ï¼ˆä½äº `relay/channel/gemini/relay-gemini.go:186`ï¼‰

è¿™æ˜¯ new-api çš„å…³é”®åˆ›æ–°ï¼Œå®ç°äº† **OpenAI æ ¼å¼ â†’ Gemini API æ ¼å¼** çš„è‡ªåŠ¨è½¬æ¢ï¼š

```go
func CovertOpenAI2Gemini(
    c *gin.Context, 
    textRequest dto.GeneralOpenAIRequest, 
    info *relaycommon.RelayInfo
) (*dto.GeminiChatRequest, error) {
    
    // 1. åˆå§‹åŒ– Gemini è¯·æ±‚ç»“æ„
    geminiRequest := dto.GeminiChatRequest{
        Contents: make([]dto.GeminiChatContent, 0, len(textRequest.Messages)),
        GenerationConfig: dto.GeminiChatGenerationConfig{
            Temperature:     textRequest.Temperature,
            TopP:            textRequest.TopP,
            MaxOutputTokens: textRequest.GetMaxTokens(),
            Seed:            int64(textRequest.Seed),
        },
    }
    
    // 2. å¤„ç†å“åº”æ¨¡æ€ï¼ˆæ–‡æœ¬ + å›¾åƒï¼‰
    if model_setting.IsGeminiModelSupportImagine(info.UpstreamModelName) {
        geminiRequest.GenerationConfig.ResponseModalities = []string{"TEXT", "IMAGE"}
    }
    
    // 3. é…ç½®æ€è€ƒæ¨¡å¼
    ThinkingAdaptor(&geminiRequest, info, textRequest)
    
    // 4. è®¾ç½®å®‰å…¨è¿‡æ»¤çº§åˆ«
    safetySettings := make([]dto.GeminiChatSafetySettings, 0)
    for _, category := range SafetySettingList {
        safetySettings = append(safetySettings, dto.GeminiChatSafetySettings{
            Category:  category,
            Threshold: model_setting.GetGeminiSafetySetting(category),
        })
    }
    geminiRequest.SafetySettings = safetySettings
    
    // 5. è½¬æ¢æ¶ˆæ¯å†…å®¹ï¼ˆè¯¦ç»†è§ä¸‹ï¼‰
    // ...
    
    return &geminiRequest, nil
}
```

#### è¯¦ç»†è½¬æ¢å†…å®¹

##### 5.1 æ¶ˆæ¯è§’è‰²æ˜ å°„

| OpenAI è§’è‰² | Gemini è§’è‰² | è¯´æ˜ |
|-------------|------------|------|
| `system` | â†’ `SystemInstructions` | ç³»ç»Ÿæç¤ºè¯ç‹¬ç«‹å­—æ®µ |
| `user` | â†’ `user` | ç”¨æˆ·æ¶ˆæ¯ï¼ˆä¿æŒä¸å˜ï¼‰ |
| `assistant` | â†’ `model` | åŠ©æ‰‹å›å¤æ˜ å°„ä¸ºæ¨¡å‹å›å¤ |
| `tool` / `function` | â†’ `user` + `FunctionResponse` | å·¥å…·è°ƒç”¨ç»“æœ |

**ä»£ç ç¤ºä¾‹**ï¼š

```go
for _, message := range textRequest.Messages {
    if message.Role == "system" {
        // ç³»ç»Ÿæ¶ˆæ¯å•ç‹¬å¤„ç†
        system_content = append(system_content, message.StringContent())
        continue
    }
    
    content := dto.GeminiChatContent{
        Role: message.Role,
    }
    
    // è§’è‰²æ˜ å°„ï¼šassistant â†’ model
    if content.Role == "assistant" {
        content.Role = "model"
    }
    
    // ... å¤„ç†æ¶ˆæ¯å†…å®¹
    geminiRequest.Contents = append(geminiRequest.Contents, content)
}

// ç»„è£…ç³»ç»ŸæŒ‡ä»¤
if len(system_content) > 0 {
    geminiRequest.SystemInstructions = &dto.GeminiChatContent{
        Parts: []dto.GeminiPart{
            {Text: strings.Join(system_content, "\n")},
        },
    }
}
```

##### 5.2 å¤šæ¨¡æ€å†…å®¹å¤„ç†

**æ”¯æŒçš„å†…å®¹ç±»å‹**ï¼š

```go
type OpenAIMessageContent struct {
    Type     string  // "text", "image_url", "file", "input_audio"
    Text     string
    ImageURL *ImageURL
    File     *FileContent
    InputAudio *InputAudioContent
}
```

**å›¾ç‰‡å¤„ç†é€»è¾‘**ï¼š

```go
for _, part := range openaiContent {
    if part.Type == dto.ContentTypeImageURL {
        imageNum++
        
        // æ£€æŸ¥å›¾ç‰‡æ•°é‡é™åˆ¶
        if constant.GeminiVisionMaxImageNum != -1 && 
           imageNum > constant.GeminiVisionMaxImageNum {
            return nil, fmt.Errorf("too many images, max allowed is %d", 
                constant.GeminiVisionMaxImageNum)
        }
        
        // åˆ¤æ–­æ˜¯ URL è¿˜æ˜¯ Base64
        if strings.HasPrefix(part.GetImageMedia().Url, "http") {
            // ä¸‹è½½ URL å¹¶è½¬æ¢ä¸º base64
            fileData, err := service.GetFileBase64FromUrl(
                c, 
                part.GetImageMedia().Url, 
                "formatting image for Gemini"
            )
            if err != nil {
                return nil, fmt.Errorf("get file from url failed: %w", err)
            }
            
            // éªŒè¯ MIME ç±»å‹ç™½åå•
            if _, ok := geminiSupportedMimeTypes[fileData.MimeType]; !ok {
                return nil, fmt.Errorf("unsupported mime type: %s", fileData.MimeType)
            }
            
            parts = append(parts, dto.GeminiPart{
                InlineData: &dto.GeminiInlineData{
                    MimeType: fileData.MimeType,
                    Data:     fileData.Base64Data,
                },
            })
        } else {
            // è§£æ Base64 æ•°æ®
            format, base64String, err := service.DecodeBase64FileData(
                part.GetImageMedia().Url
            )
            if err != nil {
                return nil, err
            }
            
            parts = append(parts, dto.GeminiPart{
                InlineData: &dto.GeminiInlineData{
                    MimeType: format,
                    Data:     base64String,
                },
            })
        }
    }
}
```

**æ”¯æŒçš„åª’ä½“ç±»å‹ç™½åå•**ï¼š

```go
var geminiSupportedMimeTypes = map[string]bool{
    // å›¾ç‰‡
    "image/png":  true,
    "image/jpeg": true,
    "image/webp": true,
    
    // è§†é¢‘
    "video/mp4":  true,
    "video/mpeg": true,
    "video/mov":  true,
    "video/avi":  true,
    "video/wmv":  true,
    
    // éŸ³é¢‘
    "audio/mp3":  true,
    "audio/mpeg": true,
    "audio/wav":  true,
    
    // æ–‡æ¡£
    "application/pdf": true,
    "text/plain":      true,
}
```

##### 5.3 å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰è½¬æ¢

```go
if textRequest.Tools != nil {
    functions := make([]dto.FunctionRequest, 0, len(textRequest.Tools))
    googleSearch := false
    codeExecution := false
    urlContext := false
    
    for _, tool := range textRequest.Tools {
        // å¤„ç†ç‰¹æ®Šå·¥å…·
        if tool.Function.Name == "googleSearch" {
            googleSearch = true
            continue
        }
        if tool.Function.Name == "codeExecution" {
            codeExecution = true
            continue
        }
        if tool.Function.Name == "urlContext" {
            urlContext = true
            continue
        }
        
        // æ¸…ç†å‚æ•°ï¼ˆç§»é™¤ Gemini ä¸æ”¯æŒçš„å­—æ®µï¼‰
        cleanedParams := cleanFunctionParameters(tool.Function.Parameters)
        tool.Function.Parameters = cleanedParams
        functions = append(functions, tool.Function)
    }
    
    // ç»„è£… Gemini å·¥å…·åˆ—è¡¨
    geminiTools := geminiRequest.GetTools()
    if codeExecution {
        geminiTools = append(geminiTools, dto.GeminiChatTool{
            CodeExecution: make(map[string]string),
        })
    }
    if googleSearch {
        geminiTools = append(geminiTools, dto.GeminiChatTool{
            GoogleSearch: make(map[string]string),
        })
    }
    if urlContext {
        geminiTools = append(geminiTools, dto.GeminiChatTool{
            URLContext: make(map[string]string),
        })
    }
    if len(functions) > 0 {
        geminiTools = append(geminiTools, dto.GeminiChatTool{
            FunctionDeclarations: functions,
        })
    }
    
    geminiRequest.SetTools(geminiTools)
}
```

**å‚æ•°æ¸…ç†å‡½æ•°**ï¼ˆç§»é™¤ Gemini ä¸æ”¯æŒçš„ JSON Schema å­—æ®µï¼‰ï¼š

```go
func cleanFunctionParameters(params interface{}) interface{} {
    switch v := params.(type) {
    case map[string]interface{}:
        cleanedMap := make(map[string]interface{})
        for k, val := range v {
            cleanedMap[k] = val
        }
        
        // ç§»é™¤ä¸æ”¯æŒçš„å­—æ®µ
        delete(cleanedMap, "default")
        delete(cleanedMap, "exclusiveMaximum")
        delete(cleanedMap, "exclusiveMinimum")
        delete(cleanedMap, "$schema")
        delete(cleanedMap, "additionalProperties")
        
        // é€’å½’æ¸…ç†åµŒå¥—ç»“æ„
        if props, ok := cleanedMap["properties"].(map[string]interface{}); ok {
            for propName, propValue := range props {
                props[propName] = cleanFunctionParameters(propValue)
            }
        }
        
        return cleanedMap
    default:
        return params
    }
}
```

##### 5.4 å“åº”æ ¼å¼ï¼ˆResponse Formatï¼‰

```go
if textRequest.ResponseFormat != nil && 
   (textRequest.ResponseFormat.Type == "json_schema" || 
    textRequest.ResponseFormat.Type == "json_object") {
    
    geminiRequest.GenerationConfig.ResponseMimeType = "application/json"
    
    if len(textRequest.ResponseFormat.JsonSchema) > 0 {
        var jsonSchema dto.FormatJsonSchema
        if err := common.Unmarshal(textRequest.ResponseFormat.JsonSchema, &jsonSchema); err == nil {
            // æ¸…ç† schema ä¸­çš„ä¸å…¼å®¹å­—æ®µ
            cleanedSchema := removeAdditionalPropertiesWithDepth(jsonSchema.Schema, 0)
            geminiRequest.GenerationConfig.ResponseSchema = cleanedSchema
        }
    }
}
```

---

### Step 4: æ„å»ºè¯·æ±‚ URLï¼ˆBuild Request URLï¼‰

åœ¨ `adaptor.go` çš„ `GetRequestURL` æ–¹æ³•ä¸­åŠ¨æ€æ„å»º API ç«¯ç‚¹ï¼š

```go
func (a *Adaptor) GetRequestURL(info *relaycommon.RelayInfo) (string, error) {
    // 1. å¤„ç†æ€è€ƒæ¨¡å¼åç¼€
    if model_setting.GetGeminiSettings().ThinkingAdapterEnabled &&
       !model_setting.ShouldPreserveThinkingSuffix(info.OriginModelName) {
        
        // ç§»é™¤ -thinking-<budget> æ ¼å¼
        if strings.Contains(info.UpstreamModelName, "-thinking-") {
            parts := strings.Split(info.UpstreamModelName, "-thinking-")
            info.UpstreamModelName = parts[0]
        } 
        // ç§»é™¤ -thinking åç¼€
        else if strings.HasSuffix(info.UpstreamModelName, "-thinking") {
            info.UpstreamModelName = strings.TrimSuffix(info.UpstreamModelName, "-thinking")
        } 
        // ç§»é™¤ -nothinking åç¼€
        else if strings.HasSuffix(info.UpstreamModelName, "-nothinking") {
            info.UpstreamModelName = strings.TrimSuffix(info.UpstreamModelName, "-nothinking")
        }
    }
    
    // 2. è·å– API ç‰ˆæœ¬ï¼ˆv1 æˆ– v1betaï¼‰
    version := model_setting.GetGeminiVersionSetting(info.UpstreamModelName)
    
    // 3. å›¾åƒç”Ÿæˆæ¨¡å‹ï¼ˆImagenï¼‰
    if strings.HasPrefix(info.UpstreamModelName, "imagen") {
        return fmt.Sprintf("%s/%s/models/%s:predict", 
            info.ChannelBaseUrl, version, info.UpstreamModelName), nil
    }
    
    // 4. åµŒå…¥æ¨¡å‹
    if strings.HasPrefix(info.UpstreamModelName, "text-embedding") ||
       strings.HasPrefix(info.UpstreamModelName, "embedding") ||
       strings.HasPrefix(info.UpstreamModelName, "gemini-embedding") {
        
        action := "embedContent"
        if info.IsGeminiBatchEmbedding {
            action = "batchEmbedContents"
        }
        return fmt.Sprintf("%s/%s/models/%s:%s", 
            info.ChannelBaseUrl, version, info.UpstreamModelName, action), nil
    }
    
    // 5. èŠå¤©å®Œæˆæ¨¡å‹
    action := "generateContent"
    if info.IsStream {
        action = "streamGenerateContent?alt=sse"
        if info.RelayMode == constant.RelayModeGemini {
            info.DisablePing = true  // åŸç”Ÿ Gemini æ ¼å¼ç¦ç”¨å¿ƒè·³
        }
    }
    
    return fmt.Sprintf("%s/%s/models/%s:%s", 
        info.ChannelBaseUrl, version, info.UpstreamModelName, action), nil
}
```

**ç”Ÿæˆçš„ URL ç¤ºä¾‹**ï¼š

```bash
# èŠå¤©å®Œæˆï¼ˆéæµå¼ï¼‰
https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-pro:generateContent

# èŠå¤©å®Œæˆï¼ˆæµå¼ï¼‰
https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-pro:streamGenerateContent?alt=sse

# åµŒå…¥ï¼ˆå•æ–‡æœ¬ï¼‰
https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent

# åµŒå…¥ï¼ˆæ‰¹é‡ï¼‰
https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents

# å›¾åƒç”Ÿæˆ
https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict
```

---

### Step 5: è®¾ç½®è¯·æ±‚å¤´ï¼ˆSetup Request Headersï¼‰

```go
func (a *Adaptor) SetupRequestHeader(
    c *gin.Context, 
    req *http.Header, 
    info *relaycommon.RelayInfo
) error {
    // è®¾ç½®é€šç”¨è¯·æ±‚å¤´
    channel.SetupApiRequestHeader(info, c, req)
    
    // Gemini ä¸“ç”¨ï¼šAPI Key é€šè¿‡è‡ªå®šä¹‰å¤´ä¼ é€’
    req.Set("x-goog-api-key", info.ApiKey)
    
    return nil
}
```

**å®Œæ•´è¯·æ±‚å¤´ç¤ºä¾‹**ï¼š

```http
POST /v1beta/models/gemini-2.0-pro:generateContent HTTP/1.1
Host: generativelanguage.googleapis.com
Content-Type: application/json
x-goog-api-key: AIzaSy...ï¼ˆå®é™… API Keyï¼‰
User-Agent: new-api/1.0
```

---

### Step 6: å‘é€è¯·æ±‚ï¼ˆSend Requestï¼‰

é€šè¿‡ `DoRequest` æ–¹æ³•å‘é€ HTTP è¯·æ±‚ï¼š

```go
func (a *Adaptor) DoRequest(
    c *gin.Context, 
    info *relaycommon.RelayInfo, 
    requestBody io.Reader
) (any, error) {
    // è°ƒç”¨é€šç”¨ API è¯·æ±‚å¤„ç†å™¨
    return channel.DoApiRequest(a, c, info, requestBody)
}
```

**å®Œæ•´ HTTP è¯·æ±‚ç¤ºä¾‹**ï¼š

```http
POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-pro:generateContent
x-goog-api-key: AIzaSy...
Content-Type: application/json

{
  "contents": [
    {
      "role": "user",
      "parts": [
        {
          "text": "Hello, Gemini!"
        }
      ]
    }
  ],
  "generationConfig": {
    "temperature": 0.7,
    "topP": 0.9,
    "maxOutputTokens": 2048
  },
  "safetySettings": [
    {
      "category": "HARM_CATEGORY_HARASSMENT",
      "threshold": "BLOCK_NONE"
    },
    {
      "category": "HARM_CATEGORY_HATE_SPEECH",
      "threshold": "BLOCK_NONE"
    }
  ]
}
```

---

### Step 7: å“åº”å¤„ç†ï¼ˆResponse Handlingï¼‰

æ ¹æ®å“åº”ç±»å‹åˆ†å‘åˆ°ä¸åŒçš„å¤„ç†å™¨ï¼š

```go
func (a *Adaptor) DoResponse(
    c *gin.Context, 
    resp *http.Response, 
    info *relaycommon.RelayInfo
) (usage any, err *types.NewAPIError) {
    
    // 1. åŸç”Ÿ Gemini æ ¼å¼æ¨¡å¼
    if info.RelayMode == constant.RelayModeGemini {
        if strings.Contains(info.RequestURLPath, ":embedContent") ||
           strings.Contains(info.RequestURLPath, ":batchEmbedContents") {
            return NativeGeminiEmbeddingHandler(c, resp, info)
        }
        if info.IsStream {
            return GeminiTextGenerationStreamHandler(c, info, resp)
        } else {
            return GeminiTextGenerationHandler(c, info, resp)
        }
    }
    
    // 2. å›¾åƒç”Ÿæˆï¼ˆImagenï¼‰
    if strings.HasPrefix(info.UpstreamModelName, "imagen") {
        return GeminiImageHandler(c, info, resp)
    }
    
    // 3. åµŒå…¥æ¨¡å‹
    if strings.HasPrefix(info.UpstreamModelName, "text-embedding") ||
       strings.HasPrefix(info.UpstreamModelName, "embedding") ||
       strings.HasPrefix(info.UpstreamModelName, "gemini-embedding") {
        return GeminiEmbeddingHandler(c, info, resp)
    }
    
    // 4. èŠå¤©å®Œæˆï¼ˆOpenAI æ ¼å¼ï¼‰
    if info.IsStream {
        return GeminiChatStreamHandler(c, info, resp)
    } else {
        return GeminiChatHandler(c, info, resp)
    }
}
```

---

### Step 8: å“åº”è½¬æ¢ï¼ˆResponse Conversionï¼‰

#### 8.1 éæµå¼å“åº”è½¬æ¢

**Gemini å“åº”ç»“æ„**ï¼š

```go
type GeminiChatResponse struct {
    Candidates []struct {
        Index   int32
        Content GeminiChatContent
        FinishReason *string
    }
    UsageMetadata struct {
        PromptTokenCount     int
        CandidatesTokenCount int
        ThoughtsTokenCount   int
        TotalTokenCount      int
        PromptTokensDetails  []struct {
            Modality   string
            TokenCount int
        }
    }
}
```

**è½¬æ¢å‡½æ•°**ï¼š

```go
func responseGeminiChat2OpenAI(
    c *gin.Context, 
    response *dto.GeminiChatResponse
) *dto.OpenAITextResponse {
    
    fullTextResponse := dto.OpenAITextResponse{
        Id:      helper.GetResponseID(c),
        Object:  "chat.completion",
        Created: common.GetTimestamp(),
        Choices: make([]dto.OpenAITextResponseChoice, 0),
    }
    
    isToolCall := false
    
    for _, candidate := range response.Candidates {
        choice := dto.OpenAITextResponseChoice{
            Index: int(candidate.Index),
            Message: dto.Message{
                Role:    "assistant",
                Content: "",
            },
            FinishReason: constant.FinishReasonStop,
        }
        
        if len(candidate.Content.Parts) > 0 {
            var texts []string
            var toolCalls []dto.ToolCallResponse
            
            for _, part := range candidate.Content.Parts {
                // å¤„ç†å†…è”æ•°æ®ï¼ˆå›¾ç‰‡/éŸ³é¢‘/è§†é¢‘ï¼‰
                if part.InlineData != nil {
                    if strings.HasPrefix(part.InlineData.MimeType, "image") {
                        imgText := "![image](data:" + part.InlineData.MimeType + 
                                   ";base64," + part.InlineData.Data + ")"
                        texts = append(texts, imgText)
                    } else {
                        texts = append(texts, fmt.Sprintf("[media](data:%s;base64,%s)", 
                            part.InlineData.MimeType, part.InlineData.Data))
                    }
                } 
                // å¤„ç†å·¥å…·è°ƒç”¨
                else if part.FunctionCall != nil {
                    choice.FinishReason = constant.FinishReasonToolCalls
                    if call := getResponseToolCall(&part); call != nil {
                        toolCalls = append(toolCalls, *call)
                    }
                } 
                // å¤„ç†æ€è€ƒå†…å®¹
                else if part.Thought {
                    choice.Message.ReasoningContent = part.Text
                } 
                // å¤„ç†ä»£ç æ‰§è¡Œ
                else {
                    if part.ExecutableCode != nil {
                        texts = append(texts, "```" + part.ExecutableCode.Language + 
                                       "\n" + part.ExecutableCode.Code + "\n```")
                    } else if part.CodeExecutionResult != nil {
                        texts = append(texts, "```output\n" + 
                                       part.CodeExecutionResult.Output + "\n```")
                    } else {
                        if part.Text != "\n" {
                            texts = append(texts, part.Text)
                        }
                    }
                }
            }
            
            if len(toolCalls) > 0 {
                choice.Message.SetToolCalls(toolCalls)
                isToolCall = true
            }
            choice.Message.SetStringContent(strings.Join(texts, "\n"))
        }
        
        // è½¬æ¢ FinishReason
        if candidate.FinishReason != nil {
            switch *candidate.FinishReason {
            case "STOP":
                choice.FinishReason = constant.FinishReasonStop
            case "MAX_TOKENS":
                choice.FinishReason = constant.FinishReasonLength
            default:
                choice.FinishReason = constant.FinishReasonContentFilter
            }
        }
        
        if isToolCall {
            choice.FinishReason = constant.FinishReasonToolCalls
        }
        
        fullTextResponse.Choices = append(fullTextResponse.Choices, choice)
    }
    
    return &fullTextResponse
}
```

#### 8.2 æµå¼å“åº”è½¬æ¢

**SSE æµå¤„ç†**ï¼š

```go
func GeminiChatStreamHandler(
    c *gin.Context, 
    info *relaycommon.RelayInfo, 
    resp *http.Response
) (*dto.Usage, *types.NewAPIError) {
    
    id := helper.GetResponseID(c)
    createAt := common.GetTimestamp()
    finishReason := constant.FinishReasonStop
    
    usage, err := geminiStreamHandler(c, info, resp, func(
        data string, 
        geminiResponse *dto.GeminiChatResponse
    ) bool {
        // è½¬æ¢ä¸º OpenAI æµå¼å“åº”æ ¼å¼
        response, isStop := streamResponseGeminiChat2OpenAI(geminiResponse)
        
        response.Id = id
        response.Created = createAt
        response.Model = info.UpstreamModelName
        
        // ç¬¬ä¸€æ¬¡å“åº”ï¼šå‘é€ç©ºå“åº”å¤´
        if info.SendResponseCount == 0 {
            emptyResponse := helper.GenerateStartEmptyResponse(
                id, createAt, info.UpstreamModelName, nil
            )
            
            // å¤„ç†å·¥å…·è°ƒç”¨çš„ç‰¹æ®Šé€»è¾‘
            if response.IsToolCall() {
                // å…ˆå‘é€å·¥å…·è°ƒç”¨æ¡†æ¶
                if len(emptyResponse.Choices) > 0 && len(response.Choices) > 0 {
                    toolCalls := response.Choices[0].Delta.ToolCalls
                    copiedToolCalls := make([]dto.ToolCallResponse, len(toolCalls))
                    for idx := range toolCalls {
                        copiedToolCalls[idx] = toolCalls[idx]
                        copiedToolCalls[idx].Function.Arguments = ""
                    }
                    emptyResponse.Choices[0].Delta.ToolCalls = copiedToolCalls
                }
                finishReason = constant.FinishReasonToolCalls
                handleStream(c, info, emptyResponse)
                
                response.ClearToolCalls()
                if response.IsFinished() {
                    response.Choices[0].FinishReason = nil
                }
            } else {
                handleStream(c, info, emptyResponse)
            }
        }
        
        // å‘é€å®é™…å†…å®¹
        handleStream(c, info, response)
        
        // å‘é€ç»“æŸæ ‡è®°
        if isStop {
            handleStream(c, info, helper.GenerateStopResponse(
                id, createAt, info.UpstreamModelName, finishReason
            ))
        }
        
        return true
    })
    
    if err != nil {
        return usage, err
    }
    
    // å‘é€æœ€ç»ˆä½¿ç”¨é‡ç»Ÿè®¡
    response := helper.GenerateFinalUsageResponse(id, createAt, info.UpstreamModelName, *usage)
    handleFinalStream(c, info, response)
    
    return usage, nil
}
```

**æµå¼å“åº”æ ¼å¼ç¤ºä¾‹**ï¼š

```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1234567890,"model":"gemini-2.0-pro","choices":[{"index":0,"delta":{"role":"assistant"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1234567890,"model":"gemini-2.0-pro","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1234567890,"model":"gemini-2.0-pro","choices":[{"index":0,"delta":{"content":"!"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1234567890,"model":"gemini-2.0-pro","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1234567890,"model":"gemini-2.0-pro","choices":[],"usage":{"prompt_tokens":10,"completion_tokens":5,"total_tokens":15}}

data: [DONE]
```

---

## ğŸ¯ ç‰¹æ®ŠåŠŸèƒ½å®ç°

### A. æ€è€ƒæ¨¡å¼ï¼ˆThinking Modeï¼‰

New-API é€šè¿‡æ¨¡å‹åç§°åç¼€å®ç°äº†å¯¹ Gemini æ€è€ƒæ¨¡å¼çš„çµæ´»æ§åˆ¶ï¼š

#### æ”¯æŒçš„åç¼€æ ¼å¼

| åç¼€æ ¼å¼ | è¯´æ˜ | ç¤ºä¾‹ |
|---------|------|------|
| `-thinking` | å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆè‡ªåŠ¨è®¡ç®—é¢„ç®—ï¼‰ | `gemini-2.5-pro-thinking` |
| `-thinking-<number>` | å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆæŒ‡å®šé¢„ç®—ï¼‰ | `gemini-2.5-pro-thinking-256` |
| `-nothinking` | å¼ºåˆ¶ç¦ç”¨æ€è€ƒæ¨¡å¼ | `gemini-2.5-flash-nothinking` |

#### å®ç°é€»è¾‘

```go
func ThinkingAdaptor(
    geminiRequest *dto.GeminiChatRequest, 
    info *relaycommon.RelayInfo, 
    oaiRequest ...dto.GeneralOpenAIRequest
) {
    if !model_setting.GetGeminiSettings().ThinkingAdapterEnabled {
        return  // æ€è€ƒé€‚é…å™¨æœªå¯ç”¨
    }
    
    modelName := info.UpstreamModelName
    
    // 1. å¤„ç† -thinking-<budget> æ ¼å¼ï¼ˆç²¾ç¡®é¢„ç®—ï¼‰
    if strings.Contains(modelName, "-thinking-") {
        parts := strings.SplitN(modelName, "-thinking-", 2)
        if len(parts) == 2 && parts[1] != "" {
            if budgetTokens, err := strconv.Atoi(parts[1]); err == nil {
                clampedBudget := clampThinkingBudget(modelName, budgetTokens)
                geminiRequest.GenerationConfig.ThinkingConfig = &dto.GeminiThinkingConfig{
                    ThinkingBudget:  common.GetPointer(clampedBudget),
                    IncludeThoughts: true,
                }
            }
        }
    } 
    // 2. å¤„ç† -thinking åç¼€ï¼ˆè‡ªåŠ¨é¢„ç®—ï¼‰
    else if strings.HasSuffix(modelName, "-thinking") {
        geminiRequest.GenerationConfig.ThinkingConfig = &dto.GeminiThinkingConfig{
            IncludeThoughts: true,
        }
        
        // å¦‚æœè®¾ç½®äº† MaxOutputTokensï¼Œè®¡ç®—æ€è€ƒé¢„ç®—
        if geminiRequest.GenerationConfig.MaxOutputTokens > 0 {
            percentage := model_setting.GetGeminiSettings().ThinkingAdapterBudgetTokensPercentage
            budgetTokens := percentage * float64(geminiRequest.GenerationConfig.MaxOutputTokens)
            clampedBudget := clampThinkingBudget(modelName, int(budgetTokens))
            geminiRequest.GenerationConfig.ThinkingConfig.ThinkingBudget = common.GetPointer(clampedBudget)
        } else if len(oaiRequest) > 0 {
            // æ ¹æ® reasoning_effort å‚æ•°è®¾ç½®é¢„ç®—
            geminiRequest.GenerationConfig.ThinkingConfig.ThinkingBudget = 
                common.GetPointer(clampThinkingBudgetByEffort(modelName, oaiRequest[0].ReasoningEffort))
        }
    } 
    // 3. å¤„ç† -nothinking åç¼€ï¼ˆå¼ºåˆ¶ç¦ç”¨ï¼‰
    else if strings.HasSuffix(modelName, "-nothinking") {
        if !isNew25ProModel(modelName) {
            geminiRequest.GenerationConfig.ThinkingConfig = &dto.GeminiThinkingConfig{
                ThinkingBudget: common.GetPointer(0),
            }
        }
    }
}
```

#### é¢„ç®—é™åˆ¶ï¼ˆBudget Clampingï¼‰

ä¸åŒæ¨¡å‹æœ‰ä¸åŒçš„æ€è€ƒé¢„ç®—èŒƒå›´ï¼š

```go
const (
    pro25MinBudget       = 128    // Gemini 2.5 Pro æœ€å°é¢„ç®—
    pro25MaxBudget       = 32768  // Gemini 2.5 Pro æœ€å¤§é¢„ç®—
    flash25MaxBudget     = 24576  // Gemini 2.5 Flash æœ€å¤§é¢„ç®—
    flash25LiteMinBudget = 512    // Gemini 2.5 Flash Lite æœ€å°é¢„ç®—
    flash25LiteMaxBudget = 24576  // Gemini 2.5 Flash Lite æœ€å¤§é¢„ç®—
)

func clampThinkingBudget(modelName string, budget int) int {
    isNew25Pro := isNew25ProModel(modelName)
    is25FlashLite := is25FlashLiteModel(modelName)
    
    if is25FlashLite {
        if budget < flash25LiteMinBudget {
            return flash25LiteMinBudget
        }
        if budget > flash25LiteMaxBudget {
            return flash25LiteMaxBudget
        }
    } else if isNew25Pro {
        if budget < pro25MinBudget {
            return pro25MinBudget
        }
        if budget > pro25MaxBudget {
            return pro25MaxBudget
        }
    } else {
        if budget < 0 {
            return 0
        }
        if budget > flash25MaxBudget {
            return flash25MaxBudget
        }
    }
    
    return budget
}
```

#### ä½¿ç”¨ç¤ºä¾‹

**ç¤ºä¾‹ 1ï¼šå¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆè‡ªåŠ¨é¢„ç®—ï¼‰**

```json
{
  "model": "gemini-2.5-pro-thinking",
  "messages": [
    {
      "role": "user",
      "content": "è§£å†³è¿™ä¸ªå¤æ‚çš„æ•°å­¦é—®é¢˜ï¼š..."
    }
  ],
  "max_tokens": 4096
}
```

è½¬æ¢åçš„ Gemini è¯·æ±‚ä¼šåŒ…å«ï¼š

```json
{
  "generationConfig": {
    "thinkingConfig": {
      "includethoughts": true,
      "thinkingBudget": 2048
    }
  }
}
```

**ç¤ºä¾‹ 2ï¼šæŒ‡å®šæ€è€ƒé¢„ç®—**

```json
{
  "model": "gemini-2.5-pro-thinking-512",
  "messages": [...]
}
```

è½¬æ¢åï¼š

```json
{
  "generationConfig": {
    "thinkingConfig": {
      "includethoughts": true,
      "thinkingBudget": 512
    }
  }
}
```

**ç¤ºä¾‹ 3ï¼šç¦ç”¨æ€è€ƒæ¨¡å¼**

```json
{
  "model": "gemini-2.5-flash-nothinking",
  "messages": [...]
}
```

è½¬æ¢åï¼š

```json
{
  "generationConfig": {
    "thinkingConfig": {
      "thinkingBudget": 0
    }
  }
}
```

---

### B. å¤šæ¨¡æ€æ”¯æŒ

#### æ”¯æŒçš„åª’ä½“ç±»å‹

New-API å®ç°äº†å®Œæ•´çš„å¤šæ¨¡æ€æ”¯æŒï¼Œèƒ½å¤Ÿè‡ªåŠ¨å¤„ç†å„ç§åª’ä½“æ ¼å¼ï¼š

```go
var geminiSupportedMimeTypes = map[string]bool{
    // å›¾ç‰‡æ ¼å¼
    "image/png":  true,
    "image/jpeg": true,
    "image/webp": true,
    
    // è§†é¢‘æ ¼å¼
    "video/mp4":    true,
    "video/mpeg":   true,
    "video/mov":    true,
    "video/avi":    true,
    "video/wmv":    true,
    "video/mpegps": true,
    "video/flv":    true,
    
    // éŸ³é¢‘æ ¼å¼
    "audio/mp3":  true,
    "audio/mpeg": true,
    "audio/wav":  true,
    
    // æ–‡æ¡£æ ¼å¼
    "application/pdf": true,
    "text/plain":      true,
}
```

#### å›¾ç‰‡å¤„ç†

**æ”¯æŒä¸¤ç§å›¾ç‰‡è¾“å…¥æ–¹å¼**ï¼š

1. **URL æ–¹å¼**ï¼š

```json
{
  "model": "gemini-1.5-pro",
  "messages": [
    {
      "role": "user",
      "content": [
        {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡"},
        {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}}
      ]
    }
  ]
}
```

**å¤„ç†æµç¨‹**ï¼š

```go
if strings.HasPrefix(part.GetImageMedia().Url, "http") {
    // 1. ä¸‹è½½å›¾ç‰‡
    fileData, err := service.GetFileBase64FromUrl(
        c, 
        part.GetImageMedia().Url, 
        "formatting image for Gemini"
    )
    if err != nil {
        return nil, fmt.Errorf("get file from url failed: %w", err)
    }
    
    // 2. éªŒè¯ MIME ç±»å‹
    if _, ok := geminiSupportedMimeTypes[strings.ToLower(fileData.MimeType)]; !ok {
        return nil, fmt.Errorf("unsupported mime type: %s", fileData.MimeType)
    }
    
    // 3. è½¬æ¢ä¸º Gemini æ ¼å¼
    parts = append(parts, dto.GeminiPart{
        InlineData: &dto.GeminiInlineData{
            MimeType: fileData.MimeType,
            Data:     fileData.Base64Data,  // Base64 ç¼–ç 
        },
    })
}
```

2. **Base64 æ–¹å¼**ï¼š

```json
{
  "model": "gemini-1.5-pro",
  "messages": [
    {
      "role": "user",
      "content": [
        {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡"},
        {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,/9j/4AAQSkZJRg..."}}
      ]
    }
  ]
}
```

**å¤„ç†æµç¨‹**ï¼š

```go
else {
    // è§£æ Base64 æ•°æ®
    format, base64String, err := service.DecodeBase64FileData(
        part.GetImageMedia().Url
    )
    if err != nil {
        return nil, fmt.Errorf("decode base64 image failed: %w", err)
    }
    
    parts = append(parts, dto.GeminiPart{
        InlineData: &dto.GeminiInlineData{
            MimeType: format,        // ä¾‹å¦‚ï¼šimage/jpeg
            Data:     base64String,  // çº¯ Base64 æ•°æ®
        },
    })
}
```

#### éŸ³é¢‘å¤„ç†

```go
if part.Type == dto.ContentTypeInputAudio {
    if part.GetInputAudio().Data == "" {
        return nil, fmt.Errorf("only base64 audio is supported")
    }
    
    base64String, err := service.DecodeBase64AudioData(part.GetInputAudio().Data)
    if err != nil {
        return nil, fmt.Errorf("decode base64 audio failed: %w", err)
    }
    
    parts = append(parts, dto.GeminiPart{
        InlineData: &dto.GeminiInlineData{
            MimeType: "audio/" + part.GetInputAudio().Format,  // ä¾‹å¦‚ï¼šaudio/mp3
            Data:     base64String,
        },
    })
}
```

#### æ–‡ä»¶å¤„ç†

```go
if part.Type == dto.ContentTypeFile {
    if part.GetFile().FileId != "" {
        return nil, fmt.Errorf("only base64 file is supported in gemini")
    }
    
    format, base64String, err := service.DecodeBase64FileData(part.GetFile().FileData)
    if err != nil {
        return nil, fmt.Errorf("decode base64 file failed: %w", err)
    }
    
    parts = append(parts, dto.GeminiPart{
        InlineData: &dto.GeminiInlineData{
            MimeType: format,
            Data:     base64String,
        },
    })
}
```

#### å›¾ç‰‡æ•°é‡é™åˆ¶

```go
imageNum := 0
for _, part := range openaiContent {
    if part.Type == dto.ContentTypeImageURL {
        imageNum++
        
        // æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶ï¼ˆé»˜è®¤ 16 å¼ ï¼‰
        if constant.GeminiVisionMaxImageNum != -1 && 
           imageNum > constant.GeminiVisionMaxImageNum {
            return nil, fmt.Errorf(
                "too many images in the message, max allowed is %d", 
                constant.GeminiVisionMaxImageNum
            )
        }
        
        // ... å¤„ç†å›¾ç‰‡
    }
}
```

**é…ç½®é™åˆ¶**ï¼š

```bash
# .env æ–‡ä»¶
GEMINI_VISION_MAX_IMAGE_NUM=16  # æœ€å¤š 16 å¼ å›¾ç‰‡
```

---

### C. å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰

#### å·¥å…·ç±»å‹

New-API æ”¯æŒä¸‰ç§å·¥å…·ç±»å‹ï¼š

1. **æ ‡å‡†å‡½æ•°å·¥å…·**ï¼ˆç”¨æˆ·è‡ªå®šä¹‰ï¼‰
2. **Google Search**ï¼ˆå†…ç½®å·¥å…·ï¼‰
3. **Code Execution**ï¼ˆä»£ç æ‰§è¡Œï¼‰
4. **URL Context**ï¼ˆURL ä¸Šä¸‹æ–‡ï¼‰

#### è½¬æ¢é€»è¾‘

```go
if textRequest.Tools != nil {
    functions := make([]dto.FunctionRequest, 0, len(textRequest.Tools))
    googleSearch := false
    codeExecution := false
    urlContext := false
    
    for _, tool := range textRequest.Tools {
        // è¯†åˆ«ç‰¹æ®Šå·¥å…·
        switch tool.Function.Name {
        case "googleSearch":
            googleSearch = true
            continue
        case "codeExecution":
            codeExecution = true
            continue
        case "urlContext":
            urlContext = true
            continue
        default:
            // æ¸…ç†å‚æ•°ï¼ˆç§»é™¤ Gemini ä¸æ”¯æŒçš„ JSON Schema å­—æ®µï¼‰
            if tool.Function.Parameters != nil {
                params, ok := tool.Function.Parameters.(map[string]interface{})
                if ok {
                    if props, hasProps := params["properties"].(map[string]interface{}); hasProps {
                        if len(props) == 0 {
                            tool.Function.Parameters = nil
                        }
                    }
                }
            }
            
            cleanedParams := cleanFunctionParameters(tool.Function.Parameters)
            tool.Function.Parameters = cleanedParams
            functions = append(functions, tool.Function)
        }
    }
    
    // ç»„è£… Gemini å·¥å…·åˆ—è¡¨
    geminiTools := geminiRequest.GetTools()
    
    if codeExecution {
        geminiTools = append(geminiTools, dto.GeminiChatTool{
            CodeExecution: make(map[string]string),
        })
    }
    
    if googleSearch {
        geminiTools = append(geminiTools, dto.GeminiChatTool{
            GoogleSearch: make(map[string]string),
        })
    }
    
    if urlContext {
        geminiTools = append(geminiTools, dto.GeminiChatTool{
            URLContext: make(map[string]string),
        })
    }
    
    if len(functions) > 0 {
        geminiTools = append(geminiTools, dto.GeminiChatTool{
            FunctionDeclarations: functions,
        })
    }
    
    geminiRequest.SetTools(geminiTools)
}
```

#### ä½¿ç”¨ç¤ºä¾‹

**ç¤ºä¾‹ 1ï¼šæ ‡å‡†å‡½æ•°å·¥å…·**

```json
{
  "model": "gemini-2.0-pro",
  "messages": [
    {"role": "user", "content": "ä»Šå¤©åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}
  ],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_weather",
        "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
        "parameters": {
          "type": "object",
          "properties": {
            "city": {
              "type": "string",
              "description": "åŸå¸‚åç§°"
            }
          },
          "required": ["city"]
        }
      }
    }
  ]
}
```

**è½¬æ¢åçš„ Gemini è¯·æ±‚**ï¼š

```json
{
  "contents": [...],
  "tools": [
    {
      "functionDeclarations": [
        {
          "name": "get_weather",
          "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
          "parameters": {
            "type": "object",
            "properties": {
              "city": {
                "type": "string",
                "description": "åŸå¸‚åç§°"
              }
            },
            "required": ["city"]
          }
        }
      ]
    }
  ]
}
```

**ç¤ºä¾‹ 2ï¼šGoogle Search**

```json
{
  "model": "gemini-2.0-pro",
  "messages": [
    {"role": "user", "content": "2024å¹´æœ€æ–°çš„AIæŠ€æœ¯è¿›å±•"}
  ],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "googleSearch"
      }
    }
  ]
}
```

**è½¬æ¢åçš„ Gemini è¯·æ±‚**ï¼š

```json
{
  "contents": [...],
  "tools": [
    {
      "googleSearch": {}
    }
  ]
}
```

**ç¤ºä¾‹ 3ï¼šCode Execution**

```json
{
  "model": "gemini-2.0-pro",
  "messages": [
    {"role": "user", "content": "è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‰10é¡¹"}
  ],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "codeExecution"
      }
    }
  ]
}
```

**è½¬æ¢åçš„ Gemini è¯·æ±‚**ï¼š

```json
{
  "contents": [...],
  "tools": [
    {
      "codeExecution": {}
    }
  ]
}
```

#### å·¥å…·è°ƒç”¨å“åº”è½¬æ¢

**Gemini å“åº”æ ¼å¼**ï¼š

```json
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "functionCall": {
              "name": "get_weather",
              "args": {
                "city": "åŒ—äº¬"
              }
            }
          }
        ]
      }
    }
  ]
}
```

**è½¬æ¢ä¸º OpenAI æ ¼å¼**ï¼š

```go
func getResponseToolCall(item *dto.GeminiPart) *dto.ToolCallResponse {
    var argsBytes []byte
    var err error
    
    if result, ok := item.FunctionCall.Arguments.(map[string]interface{}); ok {
        argsBytes, err = json.Marshal(unescapeMapOrSlice(result))
    } else {
        argsBytes, err = json.Marshal(item.FunctionCall.Arguments)
    }
    
    if err != nil {
        return nil
    }
    
    return &dto.ToolCallResponse{
        ID:   fmt.Sprintf("call_%s", common.GetUUID()),
        Type: "function",
        Function: dto.FunctionResponse{
            Arguments: string(argsBytes),
            Name:      item.FunctionCall.FunctionName,
        },
    }
}
```

**è½¬æ¢åçš„ OpenAI å“åº”**ï¼š

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "gemini-2.0-pro",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"city\":\"åŒ—äº¬\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ]
}
```

#### å·¥å…·è°ƒç”¨ç»“æœæäº¤

```go
// å·¥å…·è°ƒç”¨ç»“æœéœ€è¦ä»¥ "tool" æˆ– "function" è§’è‰²æäº¤
if message.Role == "tool" || message.Role == "function" {
    // Gemini è¦æ±‚ tool response å¿…é¡»åœ¨ user æ¶ˆæ¯ä¸­
    if len(geminiRequest.Contents) == 0 || 
       geminiRequest.Contents[len(geminiRequest.Contents)-1].Role == "model" {
        geminiRequest.Contents = append(geminiRequest.Contents, dto.GeminiChatContent{
            Role: "user",
        })
    }
    
    var parts = &geminiRequest.Contents[len(geminiRequest.Contents)-1].Parts
    name := ""
    if message.Name != nil {
        name = *message.Name
    } else if val, exists := tool_call_ids[message.ToolCallId]; exists {
        name = val
    }
    
    // è§£æå·¥å…·è¿”å›ç»“æœ
    var contentMap map[string]interface{}
    contentStr := message.StringContent()
    
    if err := json.Unmarshal([]byte(contentStr), &contentMap); err != nil {
        var contentSlice []interface{}
        if err := json.Unmarshal([]byte(contentStr), &contentSlice); err == nil {
            contentMap = map[string]interface{}{"result": contentSlice}
        } else {
            contentMap = map[string]interface{}{"content": contentStr}
        }
    }
    
    functionResp := &dto.GeminiFunctionResponse{
        Name:     name,
        Response: contentMap,
    }
    
    *parts = append(*parts, dto.GeminiPart{
        FunctionResponse: functionResp,
    })
}
```

---

### D. å®‰å…¨è®¾ç½®ï¼ˆSafety Settingsï¼‰

#### å®‰å…¨ç±»åˆ«

Gemini API æ”¯æŒå¤šä¸ªå®‰å…¨ç±»åˆ«çš„å†…å®¹è¿‡æ»¤ï¼š

```go
var SafetySettingList = []string{
    "HARM_CATEGORY_HARASSMENT",          // éªšæ‰°
    "HARM_CATEGORY_HATE_SPEECH",         // ä»‡æ¨è¨€è®º
    "HARM_CATEGORY_SEXUALLY_EXPLICIT",   // æ€§æš´éœ²å†…å®¹
    "HARM_CATEGORY_DANGEROUS_CONTENT",   // å±é™©å†…å®¹
    "HARM_CATEGORY_CIVIC_INTEGRITY",     // å…¬æ°‘è¯šä¿¡
}
```

#### é˜ˆå€¼çº§åˆ«

| é˜ˆå€¼ | è¯´æ˜ |
|------|------|
| `BLOCK_NONE` | ä¸å±è”½ä»»ä½•å†…å®¹ï¼ˆæœ€å®½æ¾ï¼‰ |
| `BLOCK_ONLY_HIGH` | ä»…å±è”½é«˜é£é™©å†…å®¹ |
| `BLOCK_MEDIUM_AND_ABOVE` | å±è”½ä¸­ç­‰åŠä»¥ä¸Šé£é™©å†…å®¹ |
| `BLOCK_LOW_AND_ABOVE` | å±è”½ä½ç­‰åŠä»¥ä¸Šé£é™©å†…å®¹ï¼ˆæœ€ä¸¥æ ¼ï¼‰ |

#### é…ç½®æ–¹å¼

**æ–¹å¼ 1ï¼šç¯å¢ƒå˜é‡**

```bash
# .env æ–‡ä»¶
GEMINI_SAFETY_SETTING=BLOCK_NONE  # é»˜è®¤è®¾ç½®ä¸ºæœ€å®½æ¾
```

**æ–¹å¼ 2ï¼šä»£ç ä¸­åŠ¨æ€é…ç½®**

```go
safetySettings := make([]dto.GeminiChatSafetySettings, 0, len(SafetySettingList))
for _, category := range SafetySettingList {
    safetySettings = append(safetySettings, dto.GeminiChatSafetySettings{
        Category:  category,
        Threshold: model_setting.GetGeminiSafetySetting(category),  // ä»é…ç½®è¯»å–
    })
}
geminiRequest.SafetySettings = safetySettings
```

**ç”Ÿæˆçš„è¯·æ±‚ç¤ºä¾‹**ï¼š

```json
{
  "contents": [...],
  "safetySettings": [
    {
      "category": "HARM_CATEGORY_HARASSMENT",
      "threshold": "BLOCK_NONE"
    },
    {
      "category": "HARM_CATEGORY_HATE_SPEECH",
      "threshold": "BLOCK_NONE"
    },
    {
      "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
      "threshold": "BLOCK_NONE"
    },
    {
      "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
      "threshold": "BLOCK_NONE"
    },
    {
      "category": "HARM_CATEGORY_CIVIC_INTEGRITY",
      "threshold": "BLOCK_NONE"
    }
  ]
}
```

#### å®‰å…¨å“åº”å¤„ç†

å½“å†…å®¹è¢«è¿‡æ»¤æ—¶ï¼ŒGemini ä¼šè¿”å›ç©ºçš„ `candidates` æ•°ç»„ï¼š

```go
if len(geminiResponse.Candidates) == 0 {
    // æ£€æŸ¥æ˜¯å¦å› å®‰å…¨è¿‡æ»¤è¢«å±è”½
    if geminiResponse.PromptFeedback != nil && 
       geminiResponse.PromptFeedback.BlockReason != nil {
        return nil, types.NewOpenAIError(
            errors.New("request blocked by Gemini API: " + *geminiResponse.PromptFeedback.BlockReason), 
            types.ErrorCodePromptBlocked, 
            http.StatusBadRequest
        )
    }
}
```

---

## ğŸ”„ å®Œæ•´è¯·æ±‚æµç¨‹å›¾

```mermaid
graph TD
    A[ç”¨æˆ·è¯·æ±‚<br/>OpenAI æ ¼å¼] --> B{èº«ä»½éªŒè¯}
    B -->|å¤±è´¥| C[è¿”å› 401 é”™è¯¯]
    B -->|æˆåŠŸ| D[è·¯ç”±åˆ†å‘<br/>router]
    
    D --> E[é€‰æ‹©é€‚é…å™¨<br/>GetAdaptor]
    E --> F{API ç±»å‹}
    F -->|Gemini| G[gemini.Adaptor]
    F -->|OpenAI| H[openai.Adaptor]
    F -->|Claude| I[claude.Adaptor]
    
    G --> J[æ ¼å¼è½¬æ¢<br/>CovertOpenAI2Gemini]
    J --> K[æ¶ˆæ¯è½¬æ¢<br/>role/content]
    J --> L[å¤šæ¨¡æ€å¤„ç†<br/>image/audio/file]
    J --> M[å·¥å…·é…ç½®<br/>tools/functions]
    J --> N[æ€è€ƒæ¨¡å¼é…ç½®<br/>thinkingConfig]
    
    K --> O[æ„å»ºè¯·æ±‚ URL<br/>GetRequestURL]
    L --> O
    M --> O
    N --> O
    
    O --> P[è®¾ç½®è¯·æ±‚å¤´<br/>x-goog-api-key]
    P --> Q[å‘é€ HTTP è¯·æ±‚<br/>DoRequest]
    
    Q --> R{å“åº”ç±»å‹}
    R -->|æµå¼| S[GeminiChatStreamHandler]
    R -->|éæµå¼| T[GeminiChatHandler]
    R -->|åµŒå…¥| U[GeminiEmbeddingHandler]
    R -->|å›¾åƒ| V[GeminiImageHandler]
    
    S --> W[å“åº”è½¬æ¢<br/>streamResponseGeminiChat2OpenAI]
    T --> X[å“åº”è½¬æ¢<br/>responseGeminiChat2OpenAI]
    U --> Y[å“åº”è½¬æ¢<br/>embedding format]
    V --> Z[å“åº”è½¬æ¢<br/>image format]
    
    W --> AA[Token è®¡è´¹]
    X --> AA
    Y --> AA
    Z --> AA
    
    AA --> AB[æ—¥å¿—è®°å½•]
    AB --> AC[è¿”å›ç»™ç”¨æˆ·<br/>OpenAI æ ¼å¼]
```

---

## ğŸ’° Token è®¡è´¹é€»è¾‘

### è®¡è´¹æ•°æ®æ¥æº

Gemini API åœ¨å“åº”ä¸­æä¾›è¯¦ç»†çš„ Token ä½¿ç”¨ç»Ÿè®¡ï¼š

```go
type GeminiChatResponse struct {
    UsageMetadata struct {
        PromptTokenCount     int  // æç¤ºè¯ Token æ•°
        CandidatesTokenCount int  // å€™é€‰å›å¤ Token æ•°
        ThoughtsTokenCount   int  // æ€è€ƒå†…å®¹ Token æ•°ï¼ˆæ€è€ƒæ¨¡å¼ä¸‹ï¼‰
        TotalTokenCount      int  // æ€» Token æ•°
        PromptTokensDetails  []struct {
            Modality   string  // æ¨¡æ€ç±»å‹ï¼šTEXT, AUDIO, IMAGE
            TokenCount int     // è¯¥æ¨¡æ€çš„ Token æ•°
        }
    }
}
```

### è®¡è´¹é€»è¾‘å®ç°

#### 1. éæµå¼å“åº”è®¡è´¹

```go
func GeminiChatHandler(
    c *gin.Context, 
    info *relaycommon.RelayInfo, 
    resp *http.Response
) (*dto.Usage, *types.NewAPIError) {
    
    // è¯»å–å¹¶è§£æå“åº”
    responseBody, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, types.NewOpenAIError(err, types.ErrorCodeBadResponseBody, http.StatusInternalServerError)
    }
    
    var geminiResponse dto.GeminiChatResponse
    err = common.Unmarshal(responseBody, &geminiResponse)
    if err != nil {
        return nil, types.NewOpenAIError(err, types.ErrorCodeBadResponseBody, http.StatusInternalServerError)
    }
    
    // è®¡ç®—ä½¿ç”¨é‡
    usage := dto.Usage{
        PromptTokens:     geminiResponse.UsageMetadata.PromptTokenCount,
        CompletionTokens: geminiResponse.UsageMetadata.CandidatesTokenCount,
        TotalTokens:      geminiResponse.UsageMetadata.TotalTokenCount,
    }
    
    // æ€è€ƒæ¨¡å¼ä¸‹å•ç‹¬ç»Ÿè®¡æ€è€ƒ Token
    usage.CompletionTokenDetails.ReasoningTokens = geminiResponse.UsageMetadata.ThoughtsTokenCount
    usage.CompletionTokens = usage.TotalTokens - usage.PromptTokens
    
    // ç»Ÿè®¡ä¸åŒæ¨¡æ€çš„ Token ä½¿ç”¨
    for _, detail := range geminiResponse.UsageMetadata.PromptTokensDetails {
        if detail.Modality == "AUDIO" {
            usage.PromptTokensDetails.AudioTokens = detail.TokenCount
        } else if detail.Modality == "TEXT" {
            usage.PromptTokensDetails.TextTokens = detail.TokenCount
        }
    }
    
    fullTextResponse.Usage = usage
    
    return &usage, nil
}
```

#### 2. æµå¼å“åº”è®¡è´¹

```go
func geminiStreamHandler(
    c *gin.Context, 
    info *relaycommon.RelayInfo, 
    resp *http.Response, 
    callback func(data string, geminiResponse *dto.GeminiChatResponse) bool
) (*dto.Usage, *types.NewAPIError) {
    
    var usage = &dto.Usage{}
    var imageCount int
    responseText := strings.Builder{}
    
    helper.StreamScannerHandler(c, resp, info, func(data string) bool {
        var geminiResponse dto.GeminiChatResponse
        err := common.UnmarshalJsonStr(data, &geminiResponse)
        if err != nil {
            logger.LogError(c, "error unmarshalling stream response: " + err.Error())
            return false
        }
        
        // ç»Ÿè®¡å›¾ç‰‡æ•°é‡ï¼ˆç”¨äºå›é€€è®¡è´¹ï¼‰
        for _, candidate := range geminiResponse.Candidates {
            for _, part := range candidate.Content.Parts {
                if part.InlineData != nil && part.InlineData.MimeType != "" {
                    imageCount++
                }
                if part.Text != "" {
                    responseText.WriteString(part.Text)
                }
            }
        }
        
        // æ›´æ–°ä½¿ç”¨é‡ç»Ÿè®¡ï¼ˆæœ€åä¸€ä¸ª chunk åŒ…å«å®Œæ•´ç»Ÿè®¡ï¼‰
        if geminiResponse.UsageMetadata.TotalTokenCount != 0 {
            usage.PromptTokens = geminiResponse.UsageMetadata.PromptTokenCount
            usage.CompletionTokens = geminiResponse.UsageMetadata.CandidatesTokenCount + 
                                     geminiResponse.UsageMetadata.ThoughtsTokenCount
            usage.CompletionTokenDetails.ReasoningTokens = geminiResponse.UsageMetadata.ThoughtsTokenCount
            usage.TotalTokens = geminiResponse.UsageMetadata.TotalTokenCount
            
            for _, detail := range geminiResponse.UsageMetadata.PromptTokensDetails {
                if detail.Modality == "AUDIO" {
                    usage.PromptTokensDetails.AudioTokens = detail.TokenCount
                } else if detail.Modality == "TEXT" {
                    usage.PromptTokensDetails.TextTokens = detail.TokenCount
                }
            }
        }
        
        return callback(data, &geminiResponse)
    })
    
    // å›é€€è®¡è´¹é€»è¾‘ï¼ˆå¦‚æœæ²¡æœ‰æ”¶åˆ° Token ç»Ÿè®¡ï¼‰
    if imageCount != 0 {
        if usage.CompletionTokens == 0 {
            usage.CompletionTokens = imageCount * 1400  // æ¯å¼ å›¾ç‰‡ä¼°ç®— 1400 tokens
        }
    }
    
    usage.PromptTokensDetails.TextTokens = usage.PromptTokens
    if usage.TotalTokens > 0 {
        usage.CompletionTokens = usage.TotalTokens - usage.PromptTokens
    }
    
    // å¦‚æœä»ç„¶æ²¡æœ‰ Token ç»Ÿè®¡ï¼Œä½¿ç”¨æ–‡æœ¬ä¼°ç®—
    if usage.CompletionTokens <= 0 {
        str := responseText.String()
        if len(str) > 0 {
            usage = service.ResponseText2Usage(c, str, info.UpstreamModelName, info.PromptTokens)
        } else {
            usage = &dto.Usage{}
        }
    }
    
    return usage, nil
}
```

#### 3. åµŒå…¥æ¨¡å‹è®¡è´¹

```go
func GeminiEmbeddingHandler(
    c *gin.Context, 
    info *relaycommon.RelayInfo, 
    resp *http.Response
) (*dto.Usage, *types.NewAPIError) {
    
    // ... å¤„ç†å“åº”
    
    // åµŒå…¥æ¨¡å‹è®¡è´¹é€»è¾‘
    // Google å°šæœªæ˜ç¡®è¯´æ˜åµŒå…¥æ¨¡å‹çš„è®¡è´¹æ–¹å¼
    // å‚è€ƒ OpenAI çš„æ–¹å¼ï¼Œä»…è®¡ç®—è¾“å…¥ Token
    usage := &dto.Usage{
        PromptTokens:     info.PromptTokens,
        CompletionTokens: 0,
        TotalTokens:      info.PromptTokens,
    }
    
    return usage, nil
}
```

#### 4. å›¾åƒç”Ÿæˆè®¡è´¹

```go
func GeminiImageHandler(
    c *gin.Context, 
    info *relaycommon.RelayInfo, 
    resp *http.Response
) (*dto.Usage, *types.NewAPIError) {
    
    // ... å¤„ç†å“åº”
    
    // å›¾åƒç”Ÿæˆè®¡è´¹é€»è¾‘
    // æ ¹æ® Google Gemini Cookbookï¼Œæ¯å¼ å›¾ç‰‡å›ºå®š 258 tokens
    const imageTokens = 258
    generatedImages := len(openAIResponse.Data)
    
    usage := &dto.Usage{
        PromptTokens:     imageTokens * generatedImages,
        CompletionTokens: 0,
        TotalTokens:      imageTokens * generatedImages,
    }
    
    return usage, nil
}
```

### è®¡è´¹æ•°æ®ç»“æ„

```go
type Usage struct {
    PromptTokens     int  // è¾“å…¥ Token æ•°
    CompletionTokens int  // è¾“å‡º Token æ•°
    TotalTokens      int  // æ€» Token æ•°
    
    // è¯¦ç»†ç»Ÿè®¡
    PromptTokensDetails struct {
        TextTokens  int  // æ–‡æœ¬ Token
        AudioTokens int  // éŸ³é¢‘ Token
        ImageTokens int  // å›¾åƒ Tokenï¼ˆç”± API å¤–éƒ¨è®¡ç®—ï¼‰
    }
    
    CompletionTokenDetails struct {
        ReasoningTokens int  // æ€è€ƒ Tokenï¼ˆæ€è€ƒæ¨¡å¼ä¸‹ï¼‰
        AudioTokens     int  // éŸ³é¢‘è¾“å‡º Token
        TextTokens      int  // æ–‡æœ¬è¾“å‡º Token
    }
}
```

### è®¡è´¹æ‰§è¡Œ

```go
// åœ¨ gemini_handler.go ä¸­æ‰§è¡Œè®¡è´¹
func GeminiHelper(c *gin.Context, info *relaycommon.RelayInfo) (newAPIError *types.NewAPIError) {
    // ... è¯·æ±‚å¤„ç†
    
    usage, openaiErr := adaptor.DoResponse(c, resp.(*http.Response), info)
    if openaiErr != nil {
        return openaiErr
    }
    
    // æ‰§è¡Œé…é¢æ‰£é™¤
    postConsumeQuota(c, info, usage.(*dto.Usage), "")
    return nil
}
```

---

## âš™ï¸ é…ç½®ç¤ºä¾‹

### ç¯å¢ƒå˜é‡é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½® Gemini ç›¸å…³å‚æ•°ï¼š

```bash
# ==========================================
# Gemini API é…ç½®
# ==========================================

# å®‰å…¨è¿‡æ»¤çº§åˆ«ï¼ˆé»˜è®¤ï¼šBLOCK_NONEï¼‰
# å¯é€‰å€¼ï¼šBLOCK_NONE, BLOCK_ONLY_HIGH, BLOCK_MEDIUM_AND_ABOVE, BLOCK_LOW_AND_ABOVE
GEMINI_SAFETY_SETTING=BLOCK_NONE

# è§†è§‰æ¨¡å‹æœ€å¤§å›¾ç‰‡æ•°é‡ï¼ˆé»˜è®¤ï¼š16ï¼‰
# è®¾ç½®ä¸º -1 è¡¨ç¤ºä¸é™åˆ¶
GEMINI_VISION_MAX_IMAGE_NUM=16

# ==========================================
# æ€è€ƒæ¨¡å¼é…ç½®ï¼ˆå¯é€‰ï¼‰
# ==========================================

# å¯ç”¨æ€è€ƒæ¨¡å¼é€‚é…å™¨ï¼ˆé»˜è®¤ï¼štrueï¼‰
GEMINI_THINKING_ADAPTER_ENABLED=true

# æ€è€ƒé¢„ç®—å æœ€å¤§è¾“å‡º Token çš„ç™¾åˆ†æ¯”ï¼ˆé»˜è®¤ï¼š0.5ï¼‰
GEMINI_THINKING_ADAPTER_BUDGET_TOKENS_PERCENTAGE=0.5

# ==========================================
# é€šç”¨é…ç½®
# ==========================================

# æ•°æ®åº“è¿æ¥ï¼ˆç¤ºä¾‹ï¼šSQLiteï¼‰
SQLITE_PATH=/data/new_api.db

# ä¼šè¯å¯†é’¥ï¼ˆå¿…é¡»è®¾ç½®ï¼‰
SESSION_SECRET=your-secure-random-session-secret-here

# åŠ å¯†å¯†é’¥ï¼ˆä½¿ç”¨ Redis æ—¶å¿…é¡»è®¾ç½®ï¼‰
CRYPTO_SECRET=your-secure-random-crypto-secret-here

# Redis è¿æ¥ï¼ˆå¯é€‰ï¼Œç”Ÿäº§ç¯å¢ƒæ¨èï¼‰
REDIS_CONN_STRING=redis://localhost:6379/0

# æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ï¼š3000ï¼‰
PORT=3000

# è°ƒè¯•æ¨¡å¼ï¼ˆé»˜è®¤ï¼šfalseï¼‰
DEBUG=false

# æµå¼å“åº”è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤ï¼š300ï¼‰
STREAMING_TIMEOUT=300

# API è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œ0 è¡¨ç¤ºä¸é™åˆ¶ï¼Œé»˜è®¤ï¼š0ï¼‰
RELAY_TIMEOUT=0
```

### æ¸ é“é…ç½®

åœ¨ç®¡ç†åå°æ·»åŠ  Gemini æ¸ é“ï¼š

#### åŸºç¡€é…ç½®

```json
{
  "id": 1,
  "type": 24,
  "name": "Google Gemini Official",
  "status": 1,
  "base_url": "https://generativelanguage.googleapis.com",
  "key": "AIzaSy...",
  "models": [
    "gemini-2.0-pro",
    "gemini-2.0-flash",
    "gemini-1.5-pro",
    "gemini-1.5-flash",
    "gemini-1.5-flash-8b",
    "text-embedding-004",
    "imagen-3.0-generate-002"
  ],
  "priority": 10,
  "weight": 100
}
```

#### é«˜çº§é…ç½®ï¼ˆJSON æ ¼å¼ï¼‰

```json
{
  "channel_setting": {
    "system_prompt": "",
    "system_prompt_override": false,
    "pass_through_body_enabled": false,
    "force_format": "",
    "thinking_to_content": false
  },
  "param_override": {
    "temperature": 0.7,
    "topP": 0.9
  },
  "model_mapping": {
    "gpt-4": "gemini-2.0-pro",
    "gpt-3.5-turbo": "gemini-2.0-flash"
  }
}
```

### æ¨¡å‹ä»·æ ¼é…ç½®

åœ¨ `pricing` è¡¨ä¸­é…ç½® Gemini æ¨¡å‹çš„ä»·æ ¼ï¼š

```sql
-- Gemini 2.0 Proï¼ˆæ€è€ƒæ¨¡å¼ï¼‰
INSERT INTO pricing (model_name, prompt_price, completion_price, reasoning_price) VALUES
('gemini-2.0-pro-thinking', 0.015, 0.060, 0.120);

-- Gemini 2.0 Proï¼ˆéæ€è€ƒæ¨¡å¼ï¼‰
INSERT INTO pricing (model_name, prompt_price, completion_price) VALUES
('gemini-2.0-pro-nothinking', 0.0125, 0.050);

-- Gemini 2.0 Flash
INSERT INTO pricing (model_name, prompt_price, completion_price) VALUES
('gemini-2.0-flash', 0.0005, 0.0015);

-- Gemini 1.5 Pro
INSERT INTO pricing (model_name, prompt_price, completion_price) VALUES
('gemini-1.5-pro', 0.0125, 0.050);

-- Gemini 1.5 Flash
INSERT INTO pricing (model_name, prompt_price, completion_price) VALUES
('gemini-1.5-flash', 0.00075, 0.0030);

-- Gemini 1.5 Flash-8B
INSERT INTO pricing (model_name, prompt_price, completion_price) VALUES
('gemini-1.5-flash-8b', 0.000375, 0.0015);

-- Text Embedding 004
INSERT INTO pricing (model_name, prompt_price, completion_price) VALUES
('text-embedding-004', 0.000025, 0);

-- Imagen 3.0
INSERT INTO pricing (model_name, prompt_price, completion_price) VALUES
('imagen-3.0-generate-002', 0.040, 0);
```

**ä»·æ ¼å•ä½è¯´æ˜**ï¼š
- ä»·æ ¼å•ä½ä¸º **USD / 1000 tokens**
- `prompt_price`: è¾“å…¥ Token ä»·æ ¼
- `completion_price`: è¾“å‡º Token ä»·æ ¼
- `reasoning_price`: æ€è€ƒ Token ä»·æ ¼ï¼ˆæ€è€ƒæ¨¡å¼ä¸‹é¢å¤–è®¡è´¹ï¼‰

### å®¢æˆ·ç«¯é…ç½®

#### ä½¿ç”¨ OpenAI Python SDK

```python
from openai import OpenAI

# é…ç½®å®¢æˆ·ç«¯
client = OpenAI(
    api_key="your-new-api-token",  # New-API ç”Ÿæˆçš„ Token
    base_url="http://localhost:3000/v1"  # New-API æœåŠ¡åœ°å€
)

# è°ƒç”¨ Gemini æ¨¡å‹ï¼ˆä½¿ç”¨ OpenAI æ ¼å¼ï¼‰
response = client.chat.completions.create(
    model="gemini-2.0-pro",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"},
        {"role": "user", "content": "è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—"}
    ],
    temperature=0.7,
    max_tokens=2048
)

print(response.choices[0].message.content)
```

#### æ€è€ƒæ¨¡å¼ç¤ºä¾‹

```python
# å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆè‡ªåŠ¨é¢„ç®—ï¼‰
response = client.chat.completions.create(
    model="gemini-2.5-pro-thinking",
    messages=[
        {"role": "user", "content": "è§£å†³è¿™ä¸ªæ•°å­¦é—®é¢˜ï¼š..."}
    ],
    max_tokens=4096
)

# æŒ‡å®šæ€è€ƒé¢„ç®—
response = client.chat.completions.create(
    model="gemini-2.5-pro-thinking-512",
    messages=[
        {"role": "user", "content": "è§£å†³è¿™ä¸ªæ•°å­¦é—®é¢˜ï¼š..."}
    ]
)

# ç¦ç”¨æ€è€ƒæ¨¡å¼
response = client.chat.completions.create(
    model="gemini-2.5-flash-nothinking",
    messages=[
        {"role": "user", "content": "ç®€å•çš„é—®ç­”ä»»åŠ¡"}
    ]
)
```

#### å¤šæ¨¡æ€ç¤ºä¾‹

```python
# å›¾ç‰‡åˆ†æ
response = client.chat.completions.create(
    model="gemini-1.5-pro",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://example.com/image.jpg"
                    }
                }
            ]
        }
    ]
)
```

#### å·¥å…·è°ƒç”¨ç¤ºä¾‹

```python
# å®šä¹‰å·¥å…·
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°"
                    }
                },
                "required": ["city"]
            }
        }
    }
]

# è°ƒç”¨
response = client.chat.completions.create(
    model="gemini-2.0-pro",
    messages=[
        {"role": "user", "content": "ä»Šå¤©åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}
    ],
    tools=tools
)

# å¤„ç†å·¥å…·è°ƒç”¨
if response.choices[0].finish_reason == "tool_calls":
    tool_call = response.choices[0].message.tool_calls[0]
    print(f"å·¥å…·åç§°: {tool_call.function.name}")
    print(f"å·¥å…·å‚æ•°: {tool_call.function.arguments}")
```

#### ä½¿ç”¨ Google Search å·¥å…·

```python
# å¯ç”¨ Google Search
response = client.chat.completions.create(
    model="gemini-2.0-pro",
    messages=[
        {"role": "user", "content": "2024å¹´æœ€æ–°çš„AIæŠ€æœ¯è¿›å±•"}
    ],
    tools=[
        {
            "type": "function",
            "function": {"name": "googleSearch"}
        }
    ]
)
```

#### ä½¿ç”¨ Code Execution å·¥å…·

```python
# å¯ç”¨ä»£ç æ‰§è¡Œ
response = client.chat.completions.create(
    model="gemini-2.0-pro",
    messages=[
        {"role": "user", "content": "è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‰20é¡¹"}
    ],
    tools=[
        {
            "type": "function",
            "function": {"name": "codeExecution"}
        }
    ]
)
```

---

## ğŸ“Š æ”¯æŒçš„ Gemini æ¨¡å‹

### èŠå¤©å®Œæˆæ¨¡å‹

```go
var ModelList = []string{
    // ===== ç¨³å®šç‰ˆæœ¬ =====
    "gemini-1.5-pro",      // æœ€å¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹
    "gemini-1.5-flash",    // å¿«é€Ÿå“åº”çš„å¤šæ¨¡æ€æ¨¡å‹
    "gemini-1.5-flash-8b", // è½»é‡çº§å¿«é€Ÿæ¨¡å‹
    "gemini-2.0-flash",    // æ–°ä¸€ä»£å¿«é€Ÿæ¨¡å‹
    
    // ===== æœ€æ–°ç‰ˆæœ¬ =====
    "gemini-1.5-pro-latest",   // 1.5 Pro æœ€æ–°ç‰ˆ
    "gemini-1.5-flash-latest", // 1.5 Flash æœ€æ–°ç‰ˆ
    
    // ===== é¢„è§ˆç‰ˆæœ¬ =====
    "gemini-2.0-flash-lite-preview", // è½»é‡çº§é¢„è§ˆç‰ˆ
    "gemini-3-pro-preview",          // ç¬¬ä¸‰ä»£é¢„è§ˆç‰ˆ
    
    // ===== å®éªŒç‰ˆæœ¬ =====
    "gemini-exp-1206",               // å®éªŒç‰ˆï¼ˆ2024-12-06ï¼‰
    "gemini-2.0-flash-exp",          // 2.0 Flash å®éªŒç‰ˆ
    "gemini-2.0-pro-exp",            // 2.0 Pro å®éªŒç‰ˆ
    
    // ===== æ€è€ƒæ¨¡å¼ =====
    "gemini-2.0-flash-thinking-exp", // Flash æ€è€ƒæ¨¡å¼å®éªŒç‰ˆ
    "gemini-2.5-pro-exp-03-25",      // 2.5 Pro å®éªŒç‰ˆ
    "gemini-2.5-pro-preview-03-25",  // 2.5 Pro é¢„è§ˆç‰ˆ
}
```

### å›¾åƒç”Ÿæˆæ¨¡å‹

```go
var ImageModelList = []string{
    "imagen-3.0-generate-002",  // Imagen 3.0 æ ‡å‡†ç‰ˆ
}
```

### åµŒå…¥æ¨¡å‹

```go
var EmbeddingModelList = []string{
    "gemini-embedding-exp-03-07",  // å®éªŒç‰ˆåµŒå…¥æ¨¡å‹
    "text-embedding-004",          // æ–‡æœ¬åµŒå…¥ 004
    "embedding-001",               // åµŒå…¥ 001
}
```

### æ¨¡å‹ç‰¹æ€§å¯¹æ¯”

| æ¨¡å‹ | ä¸Šä¸‹æ–‡é•¿åº¦ | å¤šæ¨¡æ€ | æ€è€ƒæ¨¡å¼ | å·¥å…·è°ƒç”¨ | é€‚ç”¨åœºæ™¯ |
|------|-----------|-------|---------|---------|---------|
| **gemini-2.0-pro** | 128K | âœ… | âœ… | âœ… | å¤æ‚æ¨ç†ã€é•¿æ–‡æœ¬åˆ†æ |
| **gemini-2.0-flash** | 32K | âœ… | âŒ | âœ… | å¿«é€Ÿå“åº”ã€å®æ—¶å¯¹è¯ |
| **gemini-1.5-pro** | 2M | âœ… | âŒ | âœ… | è¶…é•¿æ–‡æœ¬ã€å¤§è§„æ¨¡åˆ†æ |
| **gemini-1.5-flash** | 1M | âœ… | âŒ | âœ… | é«˜æ€§ä»·æ¯”å¤šæ¨¡æ€ |
| **gemini-1.5-flash-8b** | 1M | âœ… | âŒ | âœ… | è½»é‡çº§åº”ç”¨ |
| **gemini-2.0-flash-thinking-exp** | 32K | âœ… | âœ… | âœ… | å®éªŒæ€§æ€è€ƒæ¨¡å¼ |
| **text-embedding-004** | 2048 | âŒ | âŒ | âŒ | æ–‡æœ¬å‘é‡åŒ– |
| **imagen-3.0-generate-002** | - | âŒ | âŒ | âŒ | å›¾åƒç”Ÿæˆ |

### API ç‰ˆæœ¬æ˜ å°„

ä¸åŒæ¨¡å‹ä½¿ç”¨ä¸åŒçš„ API ç‰ˆæœ¬ï¼š

```go
func GetGeminiVersionSetting(modelName string) string {
    switch {
    case strings.HasPrefix(modelName, "gemini-2"):
        return "v1beta"  // Gemini 2.x ä½¿ç”¨ v1beta
    case strings.HasPrefix(modelName, "gemini-1.5"):
        return "v1beta"  // Gemini 1.5 ä½¿ç”¨ v1beta
    case strings.HasPrefix(modelName, "imagen"):
        return "v1"      // Imagen ä½¿ç”¨ v1
    case strings.HasPrefix(modelName, "text-embedding"):
        return "v1"      // åµŒå…¥æ¨¡å‹ä½¿ç”¨ v1
    default:
        return "v1beta"  // é»˜è®¤ä½¿ç”¨ v1beta
    }
}
```

---

## âœ¨ æ ¸å¿ƒä¼˜åŠ¿

### 1. é€æ˜é€‚é…ï¼ˆTransparent Adaptationï¼‰

ç”¨æˆ·å¯ä»¥ä½¿ç”¨ **OpenAI SDK** ç›´æ¥è°ƒç”¨ Gemini APIï¼Œæ— éœ€å­¦ä¹ æ–°çš„ API æ ¼å¼ï¼š

```python
# ä½¿ç”¨ OpenAI SDK è°ƒç”¨ Gemini
from openai import OpenAI

client = OpenAI(base_url="http://localhost:3000/v1", api_key="sk-...")
response = client.chat.completions.create(
    model="gemini-2.0-pro",  # å®é™…è°ƒç”¨ Gemini
    messages=[{"role": "user", "content": "Hello"}]
)
```

**ä¼˜åŠ¿**ï¼š
- âœ… é›¶å­¦ä¹ æˆæœ¬
- âœ… ä»£ç æ— ç¼è¿ç§»
- âœ… å·¥å…·é“¾å…¼å®¹ï¼ˆLangChainã€LlamaIndex ç­‰ï¼‰

---

### 2. æ ¼å¼è‡ªåŠ¨è½¬æ¢ï¼ˆAutomatic Format Conversionï¼‰

æ— éœ€æ‰‹åŠ¨å¤„ç†ä¸åŒ API æ ¼å¼çš„å·®å¼‚ï¼š

| åŠŸèƒ½ | OpenAI æ ¼å¼ | Gemini æ ¼å¼ | New-API å¤„ç† |
|------|------------|------------|------------|
| **è§’è‰²æ˜ å°„** | `assistant` | `model` | âœ… è‡ªåŠ¨è½¬æ¢ |
| **ç³»ç»Ÿæç¤ºè¯** | `system` æ¶ˆæ¯ | `systemInstructions` | âœ… è‡ªåŠ¨æå– |
| **å·¥å…·è°ƒç”¨** | `tools` æ•°ç»„ | `tools.functionDeclarations` | âœ… è‡ªåŠ¨è½¬æ¢ |
| **å“åº”æ ¼å¼** | `response_format` | `responseMimeType` | âœ… è‡ªåŠ¨è®¾ç½® |
| **å¤šæ¨¡æ€** | `image_url` | `inlineData` | âœ… è‡ªåŠ¨ä¸‹è½½è½¬æ¢ |

---

### 3. æ€è€ƒæ¨¡å¼å¢å¼ºï¼ˆThinking Mode Enhancementï¼‰

é€šè¿‡ç®€å•çš„æ¨¡å‹åç§°åç¼€æ§åˆ¶æ€è€ƒæ¨¡å¼ï¼š

```python
# ä¼ ç»Ÿæ–¹å¼ï¼ˆç›´æ¥è°ƒç”¨ Geminiï¼‰
response = gemini_client.generate_content(
    model="gemini-2.5-pro",
    contents=[...],
    generation_config={
        "thinking_config": {
            "thinking_budget": 256,
            "include_thoughts": True
        }
    }
)

# New-API æ–¹å¼ï¼ˆæ›´ç®€æ´ï¼‰
response = openai_client.chat.completions.create(
    model="gemini-2.5-pro-thinking-256",  # ç›´æ¥åœ¨æ¨¡å‹åç§°ä¸­æŒ‡å®š
    messages=[...]
)
```

**ä¼˜åŠ¿**ï¼š
- âœ… æ›´ç›´è§‚çš„æ§åˆ¶æ–¹å¼
- âœ… æ”¯æŒåŠ¨æ€é¢„ç®—è®¡ç®—
- âœ… å…¼å®¹ OpenAI çš„ `reasoning_effort` å‚æ•°

---

### 4. å¤šæ¨¡æ€æ— ç¼æ”¯æŒï¼ˆSeamless Multimodal Supportï¼‰

è‡ªåŠ¨å¤„ç†å›¾ç‰‡ã€è§†é¢‘ã€éŸ³é¢‘ç­‰å¤šåª’ä½“å†…å®¹ï¼š

```python
# OpenAI æ ¼å¼è¾“å…¥
response = client.chat.completions.create(
    model="gemini-1.5-pro",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡"},
                {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}}
            ]
        }
    ]
)
```

**New-API è‡ªåŠ¨å¤„ç†**ï¼š
1. âœ… ä¸‹è½½ URL å›¾ç‰‡
2. âœ… è½¬æ¢ä¸º Base64 ç¼–ç 
3. âœ… éªŒè¯ MIME ç±»å‹
4. âœ… ç»„è£…ä¸º Gemini æ ¼å¼

---

### 5. ç»Ÿä¸€è®¡è´¹ï¼ˆUnified Billingï¼‰

æ ‡å‡†åŒ–çš„ Token è®¡è´¹å’Œä½¿ç”¨ç»Ÿè®¡ï¼š

```json
{
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 50,
    "total_tokens": 150,
    "prompt_tokens_details": {
      "text_tokens": 80,
      "audio_tokens": 20
    },
    "completion_tokens_details": {
      "reasoning_tokens": 10,
      "text_tokens": 40
    }
  }
}
```

**ä¼˜åŠ¿**ï¼š
- âœ… ç»Ÿä¸€çš„è®¡è´¹æ¥å£
- âœ… è¯¦ç»†çš„ Token åˆ†è§£
- âœ… æ”¯æŒæ€è€ƒæ¨¡å¼å•ç‹¬è®¡è´¹
- âœ… å¤šæ¨¡æ€ Token åˆ†åˆ«ç»Ÿè®¡

---

### 6. æ™ºèƒ½è´Ÿè½½å‡è¡¡ï¼ˆSmart Load Balancingï¼‰

æ”¯æŒå¤šä¸ª Gemini API Key çš„è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»ï¼š

```json
{
  "channels": [
    {
      "id": 1,
      "type": 24,
      "key": "AIzaSy...key1",
      "priority": 10,
      "weight": 100,
      "status": 1
    },
    {
      "id": 2,
      "type": 24,
      "key": "AIzaSy...key2",
      "priority": 10,
      "weight": 100,
      "status": 1
    }
  ]
}
```

**è´Ÿè½½ç­–ç•¥**ï¼š
- âœ… åŠ æƒéšæœºåˆ†é…
- âœ… ä¼˜å…ˆçº§æ’åº
- âœ… è‡ªåŠ¨æ•…éšœè½¬ç§»
- âœ… å¥åº·æ£€æŸ¥

---

### 7. ä¼ä¸šçº§åŠŸèƒ½ï¼ˆEnterprise Featuresï¼‰

| åŠŸèƒ½ | è¯´æ˜ |
|------|------|
| **API Key ç®¡ç†** | ä¸ºä¸åŒç”¨æˆ·/é¡¹ç›®åˆ†é…ç‹¬ç«‹çš„ Token |
| **é…é¢ç®¡ç†** | è®¾ç½®ç”¨æˆ·çº§åˆ«çš„ä½¿ç”¨é™åˆ¶ |
| **ä½¿ç”¨ç»Ÿè®¡** | è¯¦ç»†çš„è°ƒç”¨è®°å½•å’Œç»Ÿè®¡æŠ¥è¡¨ |
| **æ¨¡å‹æ˜ å°„** | å°† OpenAI æ¨¡å‹åç§°æ˜ å°„åˆ° Gemini æ¨¡å‹ |
| **å‚æ•°è¦†ç›–** | å¼ºåˆ¶è®¾ç½®ç‰¹å®šå‚æ•°ï¼ˆå¦‚æ¸©åº¦ã€æœ€å¤§ Tokenï¼‰ |
| **ç³»ç»Ÿæç¤ºè¯** | ä¸ºæ‰€æœ‰è¯·æ±‚æ³¨å…¥ç»Ÿä¸€çš„ç³»ç»Ÿæç¤ºè¯ |
| **æ—¥å¿—å®¡è®¡** | å®Œæ•´çš„è¯·æ±‚/å“åº”æ—¥å¿—è®°å½• |
| **é€Ÿç‡é™åˆ¶** | ç”¨æˆ·çº§åˆ«å’Œæ¨¡å‹çº§åˆ«çš„è¯·æ±‚é™æµ |

---

### 8. å¼€å‘è€…å‹å¥½ï¼ˆDeveloper-Friendlyï¼‰

```python
# ç¤ºä¾‹ï¼šå¿«é€Ÿé›†æˆ
from openai import OpenAI

# æ­¥éª¤ 1: é…ç½®å®¢æˆ·ç«¯ï¼ˆä»…éœ€ä¸€æ¬¡ï¼‰
client = OpenAI(
    base_url="http://localhost:3000/v1",
    api_key="sk-your-new-api-token"
)

# æ­¥éª¤ 2: è°ƒç”¨ä»»æ„æ¨¡å‹ï¼ˆæ— éœ€ä¿®æ”¹ä»£ç ï¼‰
response = client.chat.completions.create(
    model="gemini-2.0-pro",  # åˆ‡æ¢æ¨¡å‹åªéœ€æ”¹åç§°
    messages=[{"role": "user", "content": "Hello"}]
)

# æ­¥éª¤ 3: åŒæ ·çš„ä»£ç ä¹Ÿå¯ä»¥è°ƒç”¨ Claudeã€GPT-4 ç­‰
response = client.chat.completions.create(
    model="claude-3-opus-20240229",  # æ— ç¼åˆ‡æ¢
    messages=[{"role": "user", "content": "Hello"}]
)
```

**ä¼˜åŠ¿**ï¼š
- âœ… ç»Ÿä¸€çš„æ¥å£ï¼Œå¤šä¸ªæä¾›å•†
- âœ… é™ä½ä¾›åº”å•†é”å®šé£é™©
- âœ… ç®€åŒ–æ¨¡å‹åˆ‡æ¢å’Œæµ‹è¯•
- âœ… é™ä½å­¦ä¹ å’Œç»´æŠ¤æˆæœ¬

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒä»·å€¼

New-API é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„é€‚é…å™¨æ¶æ„ï¼Œå®ç°äº†å¯¹ Google Gemini API çš„å®Œæ•´é›†æˆã€‚å…¶æ ¸å¿ƒä»·å€¼åœ¨äºï¼š

1. **ç»Ÿä¸€æ¥å£ï¼ˆUnified Interfaceï¼‰**
   - ä½¿ç”¨ OpenAI æ ‡å‡†åŒ–æ¥å£è®¿é—® Gemini
   - é™ä½å­¦ä¹ æˆæœ¬å’Œè¿ç§»æˆæœ¬
   - æé«˜ä»£ç å¤ç”¨æ€§

2. **è‡ªåŠ¨è½¬æ¢ï¼ˆAutomatic Conversionï¼‰**
   - è¯·æ±‚/å“åº”æ ¼å¼è‡ªåŠ¨è½¬æ¢
   - å¤šæ¨¡æ€å†…å®¹æ™ºèƒ½å¤„ç†
   - å·¥å…·è°ƒç”¨æ— ç¼é€‚é…

3. **åŠŸèƒ½å¢å¼ºï¼ˆFeature Enhancementï¼‰**
   - æ€è€ƒæ¨¡å¼çµæ´»æ§åˆ¶
   - å¤šæ¨¡æ€æ”¯æŒå®Œå–„
   - ä¼ä¸šçº§åŠŸèƒ½ä¸°å¯Œ

4. **ç”Ÿäº§å°±ç»ªï¼ˆProduction Readyï¼‰**
   - å®Œå–„çš„é”™è¯¯å¤„ç†
   - æµå¼å“åº”æ”¯æŒ
   - è¯¦ç»†çš„è®¡è´¹ç»Ÿè®¡
   - è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»

### æŠ€æœ¯äº®ç‚¹

| æŠ€æœ¯ç‚¹ | å®ç°æ–¹å¼ | ä¼˜åŠ¿ |
|--------|---------|------|
| **é€‚é…å™¨æ¨¡å¼** | ç»Ÿä¸€æ¥å£ï¼Œå¤šæ€å®ç° | æ˜“æ‰©å±•ã€æ˜“ç»´æŠ¤ |
| **æ ¼å¼è½¬æ¢** | åŒå‘è‡ªåŠ¨è½¬æ¢ï¼ˆOpenAI â†” Geminiï¼‰ | é€æ˜é€‚é… |
| **æµå¼å¤„ç†** | SSE æµè§£æå’Œè½¬æ¢ | å®æ—¶å“åº” |
| **å¤šæ¨¡æ€å¤„ç†** | è‡ªåŠ¨ä¸‹è½½ã€ç¼–ç ã€éªŒè¯ | ç”¨æˆ·æ— æ„ŸçŸ¥ |
| **æ€è€ƒæ¨¡å¼** | æ¨¡å‹åç§°åç¼€æ§åˆ¶ | ç›´è§‚æ˜“ç”¨ |
| **è®¡è´¹ç³»ç»Ÿ** | è¯¦ç»†çš„ Token ç»Ÿè®¡ | ç²¾ç¡®è®¡è´¹ |
| **è´Ÿè½½å‡è¡¡** | åŠ æƒéšæœº + æ•…éšœè½¬ç§» | é«˜å¯ç”¨æ€§ |

### é€‚ç”¨åœºæ™¯

âœ… **AI åº”ç”¨å¼€å‘**ï¼šå¿«é€Ÿé›†æˆå¤šä¸ª AI æä¾›å•†  
âœ… **ä¼ä¸šç½‘å…³**ï¼šç»Ÿä¸€ç®¡ç†å’Œè®¡è´¹  
âœ… **API ä¸­è½¬**ï¼šé™ä½ä¾›åº”å•†é”å®šé£é™©  
âœ… **æ¨¡å‹æµ‹è¯•**ï¼šæ–¹ä¾¿åˆ‡æ¢å’Œå¯¹æ¯”ä¸åŒæ¨¡å‹  
âœ… **æˆæœ¬ä¼˜åŒ–**ï¼šæ ¹æ®ä»»åŠ¡é€‰æ‹©æœ€ä¼˜æ¨¡å‹  

### æœªæ¥å±•æœ›

- ğŸš€ æ”¯æŒæ›´å¤š Gemini æ–°ç‰¹æ€§ï¼ˆå¦‚ Groundingï¼‰
- ğŸš€ ä¼˜åŒ–æµå¼å“åº”æ€§èƒ½
- ğŸš€ å¢å¼ºå¤šæ¨¡æ€å¤„ç†èƒ½åŠ›
- ğŸš€ å®Œå–„ä¼ä¸šçº§ç®¡ç†åŠŸèƒ½

---

## ğŸ“š ç›¸å…³èµ„æº

- **é¡¹ç›®ä¸»é¡µ**: [New-API GitHub](https://github.com/Calcium-Ion/new-api)
- **å®˜æ–¹æ–‡æ¡£**: [New-API Docs](https://docs.newapi.pro/)
- **Gemini API**: [Google AI Studio](https://aistudio.google.com/)
- **æŠ€æœ¯æ”¯æŒ**: [Community Discussion](https://docs.newapi.pro/support/community-interaction)

---

**æ–‡æ¡£ç»“æŸ**
